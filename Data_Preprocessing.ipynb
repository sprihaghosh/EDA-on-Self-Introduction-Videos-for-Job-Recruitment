{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2c64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory path\n",
    "base_dir = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\"\n",
    "\n",
    "# List of candidate folders (assuming they are named '1', '2', ..., '10')\n",
    "candidate_folders = [str(i) for i in range(1, 11)]\n",
    "\n",
    "# Define file paths for each candidate's datasets\n",
    "emotion_paths = [os.path.join(base_dir, 'emotion_data', folder, 'emotion.csv') for folder in candidate_folders]\n",
    "gaze_paths = [os.path.join(base_dir, 'emotion_data', folder, 'gaze.csv') for folder in candidate_folders]\n",
    "metadata_paths = [os.path.join(base_dir, 'emotion_data', folder, 'metadata.csv') for folder in candidate_folders]\n",
    "transcript_paths = [os.path.join(base_dir, 'transcript_data', f'{i}.csv') for i in range(1, 11)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12678da9",
   "metadata": {},
   "source": [
    "Table structures of the files provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932cb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          87 non-null     object \n",
      " 1   image_seq         87 non-null     int64  \n",
      " 2   angry             87 non-null     float64\n",
      " 3   disgust           87 non-null     float64\n",
      " 4   fear              87 non-null     float64\n",
      " 5   happy             87 non-null     float64\n",
      " 6   sad               87 non-null     float64\n",
      " 7   surprise          87 non-null     float64\n",
      " 8   neutral           87 non-null     float64\n",
      " 9   dominant_emotion  87 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 6.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88 entries, 0 to 87\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    88 non-null     object \n",
      " 1   image_seq   88 non-null     int64  \n",
      " 2   gaze        88 non-null     int64  \n",
      " 3   blink       88 non-null     int64  \n",
      " 4   eye_offset  88 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 3.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   movie_id        30 non-null     object \n",
      " 1   image_seq       30 non-null     int64  \n",
      " 2   participant_id  30 non-null     object \n",
      " 3   elapsed_time    30 non-null     float64\n",
      " 4   upload_time     30 non-null     object \n",
      " 5   distance        30 non-null     float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 1.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 18 non-null     int64  \n",
      " 1   seek               18 non-null     int64  \n",
      " 2   start              18 non-null     float64\n",
      " 3   end                18 non-null     float64\n",
      " 4   text               18 non-null     object \n",
      " 5   tokens             18 non-null     object \n",
      " 6   temperature        18 non-null     float64\n",
      " 7   avg_logprob        18 non-null     float64\n",
      " 8   compression_ratio  18 non-null     float64\n",
      " 9   no_speech_prob     18 non-null     float64\n",
      " 10  positive           18 non-null     float64\n",
      " 11  negative           18 non-null     float64\n",
      " 12  neutral            18 non-null     float64\n",
      " 13  confident          18 non-null     float64\n",
      " 14  hesitant           18 non-null     float64\n",
      " 15  concise            18 non-null     float64\n",
      " 16  enthusiastic       18 non-null     float64\n",
      " 17  speech_speed       18 non-null     float64\n",
      "dtypes: float64(14), int64(2), object(2)\n",
      "memory usage: 2.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "emotion_df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\\emotion_data\\1\\emotion.csv\")\n",
    "print(emotion_df.info())\n",
    "gaze_df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\\emotion_data\\1\\gaze.csv\")\n",
    "print(gaze_df.info())\n",
    "metadata_df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\Back_up\\Original\\emotion_data\\1\\metadata.csv\")\n",
    "print(metadata_df.info())\n",
    "transcript_df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\Back_up\\Original\\transcript_data\\1.csv\")\n",
    "print(transcript_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa848f",
   "metadata": {},
   "source": [
    "Remove Columns and Display First Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53c1977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata.csv - Candidate 1:\n",
      "    image_seq  elapsed_time\n",
      "0          6           7.0\n",
      "1          7           8.0\n",
      "Transcript Data - Candidate 1:\n",
      "    id  start   end                                               text  \\\n",
      "0   0   0.00  5.56   Hello, I am Jeffrey Shepherd and I am current...   \n",
      "1   1   5.56  9.60   IIM Coikode. I have completed my B.Tech in Bi...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.580265  0.152281  0.267454   0.846701  0.845698  0.635805      0.647783   \n",
      "1  0.550327  0.189263  0.260410   0.679283  0.733701  0.544145      0.417390   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.517986  \n",
      "1      3.217822  \n",
      "Metadata.csv - Candidate 2:\n",
      "    image_seq  elapsed_time\n",
      "0          0           1.0\n",
      "1          1           2.0\n",
      "Transcript Data - Candidate 2:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00   4.32   Hello, I am Beside You. I am Cameron Barajas ...   \n",
      "1   1   4.32  10.00   today. I recently completed my BBA in 2022. I...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.909206  0.015431  0.075362   0.976302  0.020649  0.849303      0.998064   \n",
      "1  0.660675  0.052640  0.286685   0.968629  0.741091  0.649625      0.701379   \n",
      "\n",
      "   speech_speed  \n",
      "0      4.166667  \n",
      "1      2.992958  \n",
      "Metadata.csv - Candidate 3:\n",
      "    image_seq  elapsed_time\n",
      "0          0           1.0\n",
      "1          1           2.0\n",
      "Transcript Data - Candidate 3:\n",
      "    id  start   end                                               text  \\\n",
      "0   0    0.0  3.00   My name is Michael Guzman and I am 21 years old.   \n",
      "1   1    3.0  7.36   Hailing from a small family in Varanasi, I ha...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.463382  0.253666  0.282952   0.839098  0.850701  0.628547      0.443204   \n",
      "1  0.498883  0.275251  0.225865   0.864237  0.717808  0.594307      0.382697   \n",
      "\n",
      "   speech_speed  \n",
      "0      3.666667  \n",
      "1      4.128440  \n",
      "Metadata.csv - Candidate 4:\n",
      "    image_seq  elapsed_time\n",
      "0          0           1.0\n",
      "1          1           2.0\n",
      "Transcript Data - Candidate 4:\n",
      "    id  start   end                                               text  \\\n",
      "0   0   0.00  5.12   Hello, my name is Monique Mccormick. I'm from...   \n",
      "1   1   5.12  9.12   graduate in electronics and communication fie...   \n",
      "\n",
      "   positive  negative  neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.498150  0.177770  0.32408   0.901964  0.956037  0.752856      0.752602   \n",
      "1  0.660135  0.179786  0.16008   0.662276  0.646359  0.579741      0.300230   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.734375  \n",
      "1      3.250000  \n",
      "Metadata.csv - Candidate 5:\n",
      "    image_seq  elapsed_time\n",
      "0          0           8.0\n",
      "1          1          13.0\n",
      "Transcript Data - Candidate 5:\n",
      "    id  start   end                                               text  \\\n",
      "0   0   0.00  4.84   Hello, I'm Sakshi. I come from Mumbai. I did ...   \n",
      "1   1   4.84  8.96   with specialization in advertising. I have co...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.539392  0.143638  0.316970   0.897895  0.924957  0.740309      0.693109   \n",
      "1  0.825680  0.104166  0.070154   0.732468  0.298984  0.556738      0.388407   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.892562  \n",
      "1      1.941748  \n",
      "Metadata.csv - Candidate 6:\n",
      "    image_seq  elapsed_time\n",
      "0          0           6.0\n",
      "1          1           7.0\n",
      "Transcript Data - Candidate 6:\n",
      "    id  start   end                                               text  \\\n",
      "0   0   0.00  5.28   Hi, my name is Nathan Lewis. I'm a first year...   \n",
      "1   1   5.28  9.40   Kashipur. From having a consulting experience...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.442265  0.168479  0.389255   0.814687  0.888548  0.687718      0.475202   \n",
      "1  0.625293  0.189070  0.185637   0.882211  0.733979  0.715336      0.498379   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.840909  \n",
      "1      2.669903  \n",
      "Metadata.csv - Candidate 7:\n",
      "    image_seq  elapsed_time\n",
      "0          1           2.0\n",
      "1          3           4.0\n",
      "Transcript Data - Candidate 7:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00  10.08   Hello, I am Joseph Nichols. I belong to the h...   \n",
      "1   1  10.08  16.40   in earth science from Banaras Hindu Universit...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.520804  0.168075  0.311122   0.844285  0.916887  0.674078      0.697655   \n",
      "1  0.357795  0.230645  0.411560   0.612985  0.800743  0.438345      0.301149   \n",
      "\n",
      "   speech_speed  \n",
      "0      1.785714  \n",
      "1      2.531646  \n",
      "Metadata.csv - Candidate 8:\n",
      "    image_seq  elapsed_time\n",
      "0          0           1.0\n",
      "1          1           2.0\n",
      "Transcript Data - Candidate 8:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00   6.88   Hi, hope you're doing well. I'm Srivats Biyan...   \n",
      "1   1   6.88  12.12   Now before joining IIM Co-Ecode, what all hav...   \n",
      "\n",
      "   positive  negative  neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.749869  0.073202  0.17693   0.613489  0.810735  0.677798      0.614666   \n",
      "1  0.250922  0.367668  0.38141   0.156975  0.982899  0.177705      0.087839   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.470930  \n",
      "1      3.053435  \n",
      "Metadata.csv - Candidate 9:\n",
      "    image_seq  elapsed_time\n",
      "0          0           1.0\n",
      "1          1           2.0\n",
      "Transcript Data - Candidate 9:\n",
      "    id  start   end                                               text  \\\n",
      "0   0    0.0   4.0   Hello, myself is Alexander Smith. I am a firs...   \n",
      "1   1    4.0  10.0   I come from a suburban part of India. I did m...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.529112  0.170376  0.300512   0.828881  0.904767  0.701876      0.644033   \n",
      "1  0.487809  0.257262  0.254929   0.709294  0.834372  0.578688      0.347600   \n",
      "\n",
      "   speech_speed  \n",
      "0           4.0  \n",
      "1           3.5  \n",
      "Metadata.csv - Candidate 10:\n",
      "    image_seq  elapsed_time\n",
      "0          0           1.0\n",
      "1          1           2.0\n",
      "Transcript Data - Candidate 10:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00   6.04   My name is Michael Ramos, I am from Patna, Bi...   \n",
      "1   1   6.04  12.08   I went up to do my graduation in B.Com Honour...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.457349  0.206400  0.336251   0.888680  0.881647  0.705780      0.623946   \n",
      "1  0.532671  0.222764  0.244564   0.732424  0.750270  0.620743      0.367078   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.980132  \n",
      "1      2.814570  \n"
     ]
    }
   ],
   "source": [
    "# Define columns to remove\n",
    "metadata_columns_to_remove = ['movie_id', 'participant_id', 'upload_time', 'distance']\n",
    "transcript_columns_to_remove = ['seek', 'tokens', 'temperature', 'avg_logprob', 'compression_ratio', 'no_speech_prob']\n",
    "\n",
    "# Create empty lists to store modified DataFrames\n",
    "metadata_dfs = []\n",
    "transcript_dfs = []\n",
    "\n",
    "# Loop through candidate folders\n",
    "for folder in candidate_folders:\n",
    "    metadata_path = os.path.join(base_dir, 'emotion_data', folder, 'metadata.csv')\n",
    "    transcript_path = os.path.join(base_dir, 'transcript_data', f'{folder}.csv')\n",
    "\n",
    "    # Read metadata.csv and remove specified columns\n",
    "    metadata_df = pd.read_csv(metadata_path)\n",
    "    metadata_df = metadata_df.drop(columns=metadata_columns_to_remove)\n",
    "\n",
    "    # Read transcript_data and remove specified columns\n",
    "    transcript_df = pd.read_csv(transcript_path)\n",
    "    transcript_df = transcript_df.drop(columns=transcript_columns_to_remove)\n",
    "\n",
    "    # Append modified DataFrames to the lists\n",
    "    metadata_dfs.append(metadata_df)\n",
    "    transcript_dfs.append(transcript_df)\n",
    "\n",
    "    # Display the first two rows\n",
    "    print(f\"Metadata.csv - Candidate {folder}:\\n\", metadata_df.head(2))\n",
    "    print(f\"Transcript Data - Candidate {folder}:\\n\", transcript_df.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dcb98",
   "metadata": {},
   "source": [
    "Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50dd18b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled in emotion.csv and gaze.csv.\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store modified DataFrames\n",
    "emotion_dfs = []\n",
    "gaze_dfs = []\n",
    "\n",
    "# Loop through candidate folders\n",
    "for folder in candidate_folders:\n",
    "    emotion_path = os.path.join(base_dir, 'emotion_data', folder, 'emotion.csv')\n",
    "    gaze_path = os.path.join(base_dir, 'emotion_data', folder, 'gaze.csv')\n",
    "\n",
    "    # Read emotion.csv and handle missing values\n",
    "    emotion_df = pd.read_csv(emotion_path)\n",
    "    emotion_df = emotion_df.fillna(0)  # Replace missing values with 0\n",
    "\n",
    "    # Read gaze.csv and handle missing values\n",
    "    gaze_df = pd.read_csv(gaze_path)\n",
    "    gaze_df = gaze_df.fillna(0)  # Replace missing values with 0\n",
    "\n",
    "    # Append modified DataFrames to the lists\n",
    "    emotion_dfs.append(emotion_df)\n",
    "    gaze_dfs.append(gaze_df)\n",
    "\n",
    "# Display a message confirming missing value handling\n",
    "print(\"Missing values handled in emotion.csv and gaze.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478b311",
   "metadata": {},
   "source": [
    "Removing Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d777c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows removed from emotion.csv and gaze.csv.\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store modified DataFrames\n",
    "emotion_dfs_no_duplicates = []\n",
    "gaze_dfs_no_duplicates = []\n",
    "\n",
    "# Loop through candidate folders\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    # Remove duplicates in emotion.csv\n",
    "    emotion_df_no_duplicates = emotion_dfs[i].drop_duplicates()\n",
    "\n",
    "    # Remove duplicates in gaze.csv\n",
    "    gaze_df_no_duplicates = gaze_dfs[i].drop_duplicates()\n",
    "\n",
    "    # Append modified DataFrames to the lists\n",
    "    emotion_dfs_no_duplicates.append(emotion_df_no_duplicates)\n",
    "    gaze_dfs_no_duplicates.append(gaze_df_no_duplicates)\n",
    "\n",
    "# Display a message confirming duplicate removal\n",
    "print(\"Duplicate rows removed from emotion.csv and gaze.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ed5bb",
   "metadata": {},
   "source": [
    "Description and Information of all the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67b56da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate 1 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 1):\n",
      "        image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count  87.000000  87.000000  8.700000e+01  87.000000  87.000000  87.000000   \n",
      "mean   45.390805  14.451059  6.168965e-01  18.382797   5.865318  13.575324   \n",
      "std    27.587643  18.544205  2.679399e+00  25.073562  11.237819  19.787221   \n",
      "min     0.000000   0.164384  2.400910e-10   0.079219   0.000005   0.000073   \n",
      "25%    22.500000   1.867450  8.769180e-05   1.862945   0.143215   1.845405   \n",
      "50%    44.000000   6.412790  3.443590e-03   6.366870   1.476330   5.578010   \n",
      "75%    68.500000  18.765500  6.486260e-02  21.010100   5.569355  14.056700   \n",
      "max    94.000000  71.172500  2.150890e+01  94.981800  66.222300  91.563600   \n",
      "\n",
      "        surprise    neutral  \n",
      "count  87.000000  87.000000  \n",
      "mean    8.744969  38.363648  \n",
      "std    19.621163  33.468718  \n",
      "min     0.000008   0.000117  \n",
      "25%     0.210637   8.035385  \n",
      "50%     0.970922  28.221400  \n",
      "75%     6.524355  71.227450  \n",
      "max    97.834400  97.823000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87 entries, 0 to 86\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          87 non-null     object \n",
      " 1   image_seq         87 non-null     int64  \n",
      " 2   angry             87 non-null     float64\n",
      " 3   disgust           87 non-null     float64\n",
      " 4   fear              87 non-null     float64\n",
      " 5   happy             87 non-null     float64\n",
      " 6   sad               87 non-null     float64\n",
      " 7   surprise          87 non-null     float64\n",
      " 8   neutral           87 non-null     float64\n",
      " 9   dominant_emotion  87 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 7.5+ KB\n",
      "Info for Emotion.csv (Candidate 1):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 1):\n",
      "        image_seq       gaze  blink  eye_offset\n",
      "count  88.000000  88.000000   88.0   88.000000\n",
      "mean   46.795455   0.625000    0.0   15.801362\n",
      "std    27.690058   0.486897    0.0   17.858517\n",
      "min     1.000000   0.000000    0.0  -33.465500\n",
      "25%    23.750000   0.000000    0.0    0.293050\n",
      "50%    45.500000   1.000000    0.0   19.694100\n",
      "75%    70.250000   1.000000    0.0   28.332000\n",
      "max    95.000000   1.000000    0.0   65.027600\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 88 entries, 0 to 87\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    88 non-null     object \n",
      " 1   image_seq   88 non-null     int64  \n",
      " 2   gaze        88 non-null     int64  \n",
      " 3   blink       88 non-null     int64  \n",
      " 4   eye_offset  88 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.1+ KB\n",
      "Info for Gaze.csv (Candidate 1):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 1):\n",
      "        image_seq  elapsed_time\n",
      "count  30.000000     30.000000\n",
      "mean   42.100000     41.766667\n",
      "std    26.089171     24.566143\n",
      "min     6.000000      7.000000\n",
      "25%    19.500000     19.500000\n",
      "50%    39.500000     40.500000\n",
      "75%    62.750000     61.750000\n",
      "max    91.000000     86.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     30 non-null     int64  \n",
      " 1   elapsed_time  30 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 608.0 bytes\n",
      "Info for Metadata.csv (Candidate 1):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 1):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  18.000000  18.000000  18.000000  18.000000  18.000000  18.000000   \n",
      "mean    8.500000  41.002222  45.931111   0.709199   0.141214   0.149586   \n",
      "std     5.338539  26.117009  26.294913   0.207253   0.154933   0.080974   \n",
      "min     0.000000   0.000000   5.560000   0.236254   0.004977   0.014633   \n",
      "25%     4.250000  19.680000  24.400000   0.587941   0.043334   0.082926   \n",
      "50%     8.500000  40.560000  46.640000   0.739705   0.080390   0.155741   \n",
      "75%    12.750000  62.420000  66.660000   0.870056   0.160178   0.224622   \n",
      "max    17.000000  82.720000  88.720000   0.980389   0.532010   0.267454   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  18.000000  18.000000  18.000000     18.000000     18.000000  \n",
      "mean    0.733828   0.485172   0.429418      0.466497      3.113771  \n",
      "std     0.208330   0.260785   0.272635      0.286292      0.599958  \n",
      "min     0.286049   0.008425   0.012767      0.088580      2.034884  \n",
      "25%     0.576869   0.342871   0.280775      0.211429      2.605702  \n",
      "50%     0.789854   0.407792   0.441477      0.418900      3.134206  \n",
      "75%     0.898628   0.710799   0.612890      0.686992      3.589744  \n",
      "max     0.980931   0.845698   0.919735      0.990310      4.166667  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            18 non-null     int64  \n",
      " 1   start         18 non-null     float64\n",
      " 2   end           18 non-null     float64\n",
      " 3   text          18 non-null     object \n",
      " 4   positive      18 non-null     float64\n",
      " 5   negative      18 non-null     float64\n",
      " 6   neutral       18 non-null     float64\n",
      " 7   confident     18 non-null     float64\n",
      " 8   hesitant      18 non-null     float64\n",
      " 9   concise       18 non-null     float64\n",
      " 10  enthusiastic  18 non-null     float64\n",
      " 11  speech_speed  18 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.8+ KB\n",
      "Info for Transcript Data (Candidate 1):\n",
      " None\n",
      "\n",
      "Candidate 2 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 2):\n",
      "        image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count  87.000000  87.000000  8.700000e+01  87.000000  87.000000  87.000000   \n",
      "mean   43.000000  10.395041  3.918153e-01   6.747536  35.063288  18.558391   \n",
      "std    25.258662  22.483989  1.555114e+00  13.716758  40.139694  23.306587   \n",
      "min     0.000000   0.000015  2.198970e-10   0.000002   0.011498   0.005248   \n",
      "25%    21.500000   0.098704  2.648140e-06   0.159929   1.595905   1.525660   \n",
      "50%    43.000000   0.965159  5.163640e-04   1.824250  11.561100   7.884060   \n",
      "75%    64.500000   6.389125  8.824245e-02   4.961165  80.356200  29.037500   \n",
      "max    86.000000  95.056300  1.270010e+01  82.107700  99.981800  97.396900   \n",
      "\n",
      "           surprise    neutral  \n",
      "count  8.700000e+01  87.000000  \n",
      "mean   2.267330e+00  26.576600  \n",
      "std    1.140703e+01  38.906958  \n",
      "min    8.514920e-07   0.000104  \n",
      "25%    5.336645e-03   0.122892  \n",
      "50%    5.422400e-02   1.470510  \n",
      "75%    2.809355e-01  58.685050  \n",
      "max    9.976910e+01  99.854700  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87 entries, 0 to 86\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          87 non-null     object \n",
      " 1   image_seq         87 non-null     int64  \n",
      " 2   angry             87 non-null     float64\n",
      " 3   disgust           87 non-null     float64\n",
      " 4   fear              87 non-null     float64\n",
      " 5   happy             87 non-null     float64\n",
      " 6   sad               87 non-null     float64\n",
      " 7   surprise          87 non-null     float64\n",
      " 8   neutral           87 non-null     float64\n",
      " 9   dominant_emotion  87 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 7.5+ KB\n",
      "Info for Emotion.csv (Candidate 2):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 2):\n",
      "        image_seq       gaze      blink  eye_offset\n",
      "count  87.000000  87.000000  87.000000   87.000000\n",
      "mean   44.000000   0.609195   0.045977   21.768546\n",
      "std    25.258662   0.490759   0.210649   15.619435\n",
      "min     1.000000   0.000000   0.000000  -15.240500\n",
      "25%    22.500000   0.000000   0.000000   11.852200\n",
      "50%    44.000000   1.000000   0.000000   20.370000\n",
      "75%    65.500000   1.000000   0.000000   29.883100\n",
      "max    87.000000   1.000000   1.000000   67.671000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87 entries, 0 to 86\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    87 non-null     object \n",
      " 1   image_seq   87 non-null     int64  \n",
      " 2   gaze        87 non-null     int64  \n",
      " 3   blink       87 non-null     int64  \n",
      " 4   eye_offset  87 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.1+ KB\n",
      "Info for Gaze.csv (Candidate 2):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 2):\n",
      "        image_seq  elapsed_time\n",
      "count  87.000000     87.000000\n",
      "mean   43.000000     44.540230\n",
      "std    25.258662     26.018243\n",
      "min     0.000000      1.000000\n",
      "25%    21.500000     22.500000\n",
      "50%    43.000000     44.000000\n",
      "75%    64.500000     65.500000\n",
      "max    86.000000     90.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     87 non-null     int64  \n",
      " 1   elapsed_time  87 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.5 KB\n",
      "Info for Metadata.csv (Candidate 2):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 2):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  19.000000  19.000000  19.000000  19.000000  19.000000  19.000000   \n",
      "mean    9.000000  44.327368  49.049474   0.722006   0.107541   0.170453   \n",
      "std     5.627314  27.878086  27.551765   0.160438   0.083733   0.101724   \n",
      "min     0.000000   0.000000   4.320000   0.445882   0.004820   0.011082   \n",
      "25%     4.500000  22.770000  27.500000   0.617760   0.050085   0.089083   \n",
      "50%     9.000000  43.880000  49.160000   0.705166   0.103343   0.165050   \n",
      "75%    13.500000  66.620000  72.260000   0.852049   0.139718   0.238241   \n",
      "max    18.000000  88.960000  89.760000   0.983976   0.309697   0.414358   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  19.000000  19.000000  19.000000     19.000000     19.000000  \n",
      "mean    0.684879   0.436158   0.484221      0.516685      3.269092  \n",
      "std     0.239694   0.325049   0.246994      0.307049      0.440166  \n",
      "min     0.252384   0.002186   0.091963      0.107444      2.483444  \n",
      "25%     0.453661   0.079168   0.264890      0.282396      3.011630  \n",
      "50%     0.772993   0.523318   0.506651      0.407736      3.244275  \n",
      "75%     0.821340   0.707268   0.671099      0.787675      3.484713  \n",
      "max     0.993897   0.885920   0.892335      0.998064      4.166667  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            19 non-null     int64  \n",
      " 1   start         19 non-null     float64\n",
      " 2   end           19 non-null     float64\n",
      " 3   text          19 non-null     object \n",
      " 4   positive      19 non-null     float64\n",
      " 5   negative      19 non-null     float64\n",
      " 6   neutral       19 non-null     float64\n",
      " 7   confident     19 non-null     float64\n",
      " 8   hesitant      19 non-null     float64\n",
      " 9   concise       19 non-null     float64\n",
      " 10  enthusiastic  19 non-null     float64\n",
      " 11  speech_speed  19 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.9+ KB\n",
      "Info for Transcript Data (Candidate 2):\n",
      " None\n",
      "\n",
      "Candidate 3 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 3):\n",
      "         image_seq       angry       disgust        fear       happy  \\\n",
      "count  100.000000  100.000000  1.000000e+02  100.000000  100.000000   \n",
      "mean    49.500000    1.531082  1.846983e-03   21.633298   21.428420   \n",
      "std     29.011492    4.683116  7.318047e-03   24.906563   23.409376   \n",
      "min      0.000000    0.000017  1.924780e-12    0.003125    0.002380   \n",
      "25%     24.750000    0.048191  2.133243e-07    2.604662    3.423355   \n",
      "50%     49.500000    0.384763  2.660785e-05   10.101240   13.237950   \n",
      "75%     74.250000    1.101012  3.186135e-04   36.418800   30.653125   \n",
      "max     99.000000   42.171200  5.464910e-02   95.139500   95.781900   \n",
      "\n",
      "              sad    surprise     neutral  \n",
      "count  100.000000  100.000000  100.000000  \n",
      "mean    10.295898    7.268728   37.840726  \n",
      "std     17.599308   19.010296   32.812847  \n",
      "min      0.004126    0.000029    0.021739  \n",
      "25%      0.499891    0.153879    7.150482  \n",
      "50%      2.485550    0.931967   30.483550  \n",
      "75%      9.359340    3.586158   65.437775  \n",
      "max     98.309400   91.265300   99.918800  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 99\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          100 non-null    object \n",
      " 1   image_seq         100 non-null    int64  \n",
      " 2   angry             100 non-null    float64\n",
      " 3   disgust           100 non-null    float64\n",
      " 4   fear              100 non-null    float64\n",
      " 5   happy             100 non-null    float64\n",
      " 6   sad               100 non-null    float64\n",
      " 7   surprise          100 non-null    float64\n",
      " 8   neutral           100 non-null    float64\n",
      " 9   dominant_emotion  100 non-null    object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 8.6+ KB\n",
      "Info for Emotion.csv (Candidate 3):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 3):\n",
      "         image_seq    gaze       blink  eye_offset\n",
      "count  100.000000  100.00  100.000000  100.000000\n",
      "mean    50.500000    0.45    0.070000   30.137213\n",
      "std     29.011492    0.50    0.256432   18.909401\n",
      "min      1.000000    0.00    0.000000   -4.008000\n",
      "25%     25.750000    0.00    0.000000   16.542750\n",
      "50%     50.500000    0.00    0.000000   27.994050\n",
      "75%     75.250000    1.00    0.000000   41.106175\n",
      "max    100.000000    1.00    1.000000   91.234700\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    100 non-null    object \n",
      " 1   image_seq   100 non-null    int64  \n",
      " 2   gaze        100 non-null    int64  \n",
      " 3   blink       100 non-null    int64  \n",
      " 4   eye_offset  100 non-null    float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.7+ KB\n",
      "Info for Gaze.csv (Candidate 3):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 3):\n",
      "         image_seq  elapsed_time\n",
      "count  100.000000    100.000000\n",
      "mean    49.500000     50.500000\n",
      "std     29.011492     29.011492\n",
      "min      0.000000      1.000000\n",
      "25%     24.750000     25.750000\n",
      "50%     49.500000     50.500000\n",
      "75%     74.250000     75.250000\n",
      "max     99.000000    100.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     100 non-null    int64  \n",
      " 1   elapsed_time  100 non-null    float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.7 KB\n",
      "Info for Metadata.csv (Candidate 3):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 3):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  28.000000  28.000000  28.000000  28.000000  28.000000  28.000000   \n",
      "mean   13.500000  50.020000  53.523571   0.567257   0.264337   0.168406   \n",
      "std     8.225975  30.683965  30.359964   0.283258   0.251135   0.111868   \n",
      "min     0.000000   0.000000   3.000000   0.010479   0.002975   0.004540   \n",
      "25%     6.750000  24.320000  29.770000   0.394705   0.094690   0.074649   \n",
      "50%    13.500000  49.780000  53.520000   0.581371   0.214144   0.171494   \n",
      "75%    20.250000  75.070000  78.770000   0.805528   0.363048   0.247356   \n",
      "max    27.000000  97.600000  98.100000   0.992485   0.971378   0.382125   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  28.000000  28.000000  28.000000     28.000000     28.000000  \n",
      "mean    0.573566   0.604004   0.394715      0.448050      3.385636  \n",
      "std     0.321698   0.234894   0.232922      0.312083      0.867994  \n",
      "min     0.001164   0.001167   0.006319      0.004134      1.000000  \n",
      "25%     0.334525   0.477667   0.178582      0.179011      2.963017  \n",
      "50%     0.697194   0.606533   0.404061      0.426116      3.558000  \n",
      "75%     0.814442   0.782730   0.580721      0.725450      4.000000  \n",
      "max     0.992362   0.994522   0.887560      0.995513      4.945055  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            28 non-null     int64  \n",
      " 1   start         28 non-null     float64\n",
      " 2   end           28 non-null     float64\n",
      " 3   text          28 non-null     object \n",
      " 4   positive      28 non-null     float64\n",
      " 5   negative      28 non-null     float64\n",
      " 6   neutral       28 non-null     float64\n",
      " 7   confident     28 non-null     float64\n",
      " 8   hesitant      28 non-null     float64\n",
      " 9   concise       28 non-null     float64\n",
      " 10  enthusiastic  28 non-null     float64\n",
      " 11  speech_speed  28 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 2.8+ KB\n",
      "Info for Transcript Data (Candidate 3):\n",
      " None\n",
      "\n",
      "Candidate 4 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 4):\n",
      "        image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count  99.000000  99.000000  9.900000e+01  99.000000  99.000000  99.000000   \n",
      "mean   49.000000   1.734140  3.365219e-04   2.602291   0.572650   1.057942   \n",
      "std    28.722813   2.627746  1.533258e-03   6.784930   2.402168   2.492823   \n",
      "min     0.000000   0.000722  9.403450e-13   0.000546   0.000009   0.000251   \n",
      "25%    24.500000   0.096085  1.153220e-08   0.044912   0.002360   0.023519   \n",
      "50%    49.000000   0.603546  1.152230e-06   0.251244   0.021476   0.245196   \n",
      "75%    73.500000   2.105545  1.982120e-05   1.427960   0.228083   0.828137   \n",
      "max    98.000000  12.977300  1.074940e-02  54.999700  21.394600  17.941200   \n",
      "\n",
      "        surprise   neutral  \n",
      "count  99.000000  99.00000  \n",
      "mean    1.403702  92.62894  \n",
      "std     4.309405  12.46486  \n",
      "min     0.000153  31.88270  \n",
      "25%     0.004437  91.88845  \n",
      "50%     0.050619  98.10390  \n",
      "75%     0.546825  99.65325  \n",
      "max    31.586400  99.99140  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99 entries, 0 to 98\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          99 non-null     object \n",
      " 1   image_seq         99 non-null     int64  \n",
      " 2   angry             99 non-null     float64\n",
      " 3   disgust           99 non-null     float64\n",
      " 4   fear              99 non-null     float64\n",
      " 5   happy             99 non-null     float64\n",
      " 6   sad               99 non-null     float64\n",
      " 7   surprise          99 non-null     float64\n",
      " 8   neutral           99 non-null     float64\n",
      " 9   dominant_emotion  99 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 8.5+ KB\n",
      "Info for Emotion.csv (Candidate 4):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 4):\n",
      "        image_seq       gaze      blink  eye_offset\n",
      "count  99.000000  99.000000  99.000000   99.000000\n",
      "mean   50.000000   0.787879   0.212121   12.492482\n",
      "std    28.722813   0.410891   0.410891   20.419822\n",
      "min     1.000000   0.000000   0.000000   -7.950900\n",
      "25%    25.500000   1.000000   0.000000    0.804150\n",
      "50%    50.000000   1.000000   0.000000    4.546400\n",
      "75%    74.500000   1.000000   0.000000   10.922200\n",
      "max    99.000000   1.000000   1.000000   77.762900\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99 entries, 0 to 98\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    99 non-null     object \n",
      " 1   image_seq   99 non-null     int64  \n",
      " 2   gaze        99 non-null     int64  \n",
      " 3   blink       99 non-null     int64  \n",
      " 4   eye_offset  99 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.6+ KB\n",
      "Info for Gaze.csv (Candidate 4):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 4):\n",
      "        image_seq  elapsed_time\n",
      "count  99.000000     99.000000\n",
      "mean   49.000000     50.000000\n",
      "std    28.722813     28.722813\n",
      "min     0.000000      1.000000\n",
      "25%    24.500000     25.500000\n",
      "50%    49.000000     50.000000\n",
      "75%    73.500000     74.500000\n",
      "max    98.000000     99.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     99 non-null     int64  \n",
      " 1   elapsed_time  99 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.7 KB\n",
      "Info for Metadata.csv (Candidate 4):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 4):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  19.000000  19.000000  19.000000  19.000000  19.000000  19.000000   \n",
      "mean    9.000000  46.922105  52.128421   0.655748   0.169142   0.175110   \n",
      "std     5.627314  30.929300  30.917702   0.202528   0.127333   0.094914   \n",
      "min     0.000000   0.000000   5.120000   0.233843   0.022971   0.041169   \n",
      "25%     4.500000  21.780000  26.960000   0.539352   0.063528   0.099623   \n",
      "50%     9.000000  44.960000  50.080000   0.670338   0.147361   0.178128   \n",
      "75%    13.500000  71.260000  77.680000   0.807720   0.227101   0.226315   \n",
      "max    18.000000  97.840000  98.920000   0.934200   0.523588   0.399228   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  19.000000  19.000000  19.000000     19.000000     19.000000  \n",
      "mean    0.621740   0.570452   0.403479      0.440626      2.775454  \n",
      "std     0.241377   0.206873   0.172476      0.259141      0.385879  \n",
      "min     0.012007   0.070168   0.131713      0.014493      2.127660  \n",
      "25%     0.545891   0.454399   0.283555      0.235713      2.492817  \n",
      "50%     0.662276   0.591770   0.406291      0.352678      2.685950  \n",
      "75%     0.786613   0.709301   0.537570      0.655533      3.125000  \n",
      "max     0.901964   0.956037   0.752856      0.973929      3.448276  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            19 non-null     int64  \n",
      " 1   start         19 non-null     float64\n",
      " 2   end           19 non-null     float64\n",
      " 3   text          19 non-null     object \n",
      " 4   positive      19 non-null     float64\n",
      " 5   negative      19 non-null     float64\n",
      " 6   neutral       19 non-null     float64\n",
      " 7   confident     19 non-null     float64\n",
      " 8   hesitant      19 non-null     float64\n",
      " 9   concise       19 non-null     float64\n",
      " 10  enthusiastic  19 non-null     float64\n",
      " 11  speech_speed  19 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.9+ KB\n",
      "Info for Transcript Data (Candidate 4):\n",
      " None\n",
      "\n",
      "Candidate 5 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 5):\n",
      "        image_seq      angry       disgust      fear     happy       sad  \\\n",
      "count   4.000000   4.000000  4.000000e+00  4.000000  4.000000  4.000000   \n",
      "mean    1.500000   6.261661  1.663967e-05  0.202875  0.101414  0.654111   \n",
      "std     1.290994  12.427496  3.327902e-05  0.405233  0.153454  1.238380   \n",
      "min     0.000000   0.006253  2.913510e-11  0.000096  0.001305  0.008517   \n",
      "25%     0.750000   0.025912  4.424227e-11  0.000125  0.003659  0.017378   \n",
      "50%     1.500000   0.068795  2.236250e-10  0.000340  0.039153  0.048389   \n",
      "75%     2.250000   6.304545  1.663985e-05  0.203090  0.136908  0.685123   \n",
      "max     3.000000  24.902800  6.655820e-05  0.810725  0.326047  2.511150   \n",
      "\n",
      "       surprise    neutral  \n",
      "count  4.000000   4.000000  \n",
      "mean   0.008069  92.771850  \n",
      "std    0.014569  14.019343  \n",
      "min    0.000012  71.744100  \n",
      "25%    0.000040  92.609700  \n",
      "50%    0.001201  99.717200  \n",
      "75%    0.009230  99.879350  \n",
      "max    0.029861  99.908900  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4 entries, 0 to 3\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          4 non-null      object \n",
      " 1   image_seq         4 non-null      int64  \n",
      " 2   angry             4 non-null      float64\n",
      " 3   disgust           4 non-null      float64\n",
      " 4   fear              4 non-null      float64\n",
      " 5   happy             4 non-null      float64\n",
      " 6   sad               4 non-null      float64\n",
      " 7   surprise          4 non-null      float64\n",
      " 8   neutral           4 non-null      float64\n",
      " 9   dominant_emotion  4 non-null      object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 352.0+ bytes\n",
      "Info for Emotion.csv (Candidate 5):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 5):\n",
      "        image_seq  gaze  blink  eye_offset\n",
      "count   4.000000   4.0   4.00    4.000000\n",
      "mean    2.500000   1.0   0.25  -15.802625\n",
      "std     1.290994   0.0   0.50    5.849439\n",
      "min     1.000000   1.0   0.00  -22.602000\n",
      "25%     1.750000   1.0   0.00  -18.381675\n",
      "50%     2.500000   1.0   0.00  -16.101300\n",
      "75%     3.250000   1.0   0.25  -13.522250\n",
      "max     4.000000   1.0   1.00   -8.405900\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4 entries, 0 to 3\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    4 non-null      object \n",
      " 1   image_seq   4 non-null      int64  \n",
      " 2   gaze        4 non-null      int64  \n",
      " 3   blink       4 non-null      int64  \n",
      " 4   eye_offset  4 non-null      float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 192.0+ bytes\n",
      "Info for Gaze.csv (Candidate 5):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 5):\n",
      "        image_seq  elapsed_time\n",
      "count   4.000000      4.000000\n",
      "mean    1.500000     35.500000\n",
      "std     1.290994     30.424771\n",
      "min     0.000000      8.000000\n",
      "25%     0.750000     11.750000\n",
      "50%     1.500000     31.000000\n",
      "75%     2.250000     54.750000\n",
      "max     3.000000     72.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     4 non-null      int64  \n",
      " 1   elapsed_time  4 non-null      float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 192.0 bytes\n",
      "Info for Metadata.csv (Candidate 5):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 5):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  17.000000  17.000000  17.000000  17.000000  17.000000  17.000000   \n",
      "mean    8.000000  34.283529  38.667059   0.630573   0.187013   0.182414   \n",
      "std     5.049752  21.243722  21.415071   0.196547   0.174789   0.080020   \n",
      "min     0.000000   0.000000   4.840000   0.104820   0.011025   0.035960   \n",
      "25%     4.000000  16.880000  22.000000   0.539392   0.100235   0.139609   \n",
      "50%     8.000000  34.280000  38.480000   0.666163   0.143638   0.183636   \n",
      "75%    12.000000  51.760000  55.440000   0.686997   0.267005   0.225224   \n",
      "max    16.000000  67.520000  74.520000   0.950391   0.755571   0.316970   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  17.000000  17.000000  17.000000     17.000000     17.000000  \n",
      "mean    0.590094   0.461488   0.413644      0.378110      2.817341  \n",
      "std     0.261988   0.253343   0.233565      0.251527      0.705604  \n",
      "min     0.065768   0.007717   0.046411      0.011409      1.857143  \n",
      "25%     0.417246   0.301754   0.297613      0.187111      2.272727  \n",
      "50%     0.650230   0.539980   0.344343      0.412160      2.777778  \n",
      "75%     0.737882   0.631814   0.471627      0.464803      3.197674  \n",
      "max     0.897895   0.924957   0.961038      0.903439      4.225352  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            17 non-null     int64  \n",
      " 1   start         17 non-null     float64\n",
      " 2   end           17 non-null     float64\n",
      " 3   text          17 non-null     object \n",
      " 4   positive      17 non-null     float64\n",
      " 5   negative      17 non-null     float64\n",
      " 6   neutral       17 non-null     float64\n",
      " 7   confident     17 non-null     float64\n",
      " 8   hesitant      17 non-null     float64\n",
      " 9   concise       17 non-null     float64\n",
      " 10  enthusiastic  17 non-null     float64\n",
      " 11  speech_speed  17 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.7+ KB\n",
      "Info for Transcript Data (Candidate 5):\n",
      " None\n",
      "\n",
      "Candidate 6 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 6):\n",
      "        image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count    14.0000  14.000000  1.400000e+01  14.000000  14.000000  14.000000   \n",
      "mean      6.5000   0.004150  2.845287e-07   0.035453  22.363658   0.436512   \n",
      "std       4.1833   0.005592  3.189387e-07   0.038552  13.685238   0.515204   \n",
      "min       0.0000   0.000589  8.565390e-08   0.009689   4.029290   0.142390   \n",
      "25%       3.2500   0.001167  9.763400e-08   0.011825  11.040150   0.164553   \n",
      "50%       6.5000   0.001322  1.417950e-07   0.016607  30.083650   0.178928   \n",
      "75%       9.7500   0.001975  1.759498e-07   0.026713  33.227100   0.217362   \n",
      "max      13.0000   0.014587  8.826870e-07   0.106949  37.142700   1.394150   \n",
      "\n",
      "        surprise    neutral  \n",
      "count  14.000000  14.000000  \n",
      "mean    0.004707  77.155543  \n",
      "std     0.002990  13.272423  \n",
      "min     0.000761  62.656300  \n",
      "25%     0.002637  66.603050  \n",
      "50%     0.004929  69.743700  \n",
      "75%     0.007142  88.721550  \n",
      "max     0.008271  94.465500  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14 entries, 0 to 13\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          14 non-null     object \n",
      " 1   image_seq         14 non-null     int64  \n",
      " 2   angry             14 non-null     float64\n",
      " 3   disgust           14 non-null     float64\n",
      " 4   fear              14 non-null     float64\n",
      " 5   happy             14 non-null     float64\n",
      " 6   sad               14 non-null     float64\n",
      " 7   surprise          14 non-null     float64\n",
      " 8   neutral           14 non-null     float64\n",
      " 9   dominant_emotion  14 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 1.2+ KB\n",
      "Info for Emotion.csv (Candidate 6):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 6):\n",
      "        image_seq  gaze  blink  eye_offset\n",
      "count    14.0000  14.0   14.0   14.000000\n",
      "mean      7.5000   1.0    0.0   -1.707193\n",
      "std       4.1833   0.0    0.0    0.322101\n",
      "min       1.0000   1.0    0.0   -2.146300\n",
      "25%       4.2500   1.0    0.0   -1.971350\n",
      "50%       7.5000   1.0    0.0   -1.672150\n",
      "75%      10.7500   1.0    0.0   -1.538900\n",
      "max      14.0000   1.0    0.0   -1.163300\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14 entries, 0 to 13\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    14 non-null     object \n",
      " 1   image_seq   14 non-null     int64  \n",
      " 2   gaze        14 non-null     int64  \n",
      " 3   blink       14 non-null     int64  \n",
      " 4   eye_offset  14 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 672.0+ bytes\n",
      "Info for Gaze.csv (Candidate 6):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 6):\n",
      "        image_seq  elapsed_time\n",
      "count    14.0000       14.0000\n",
      "mean      6.5000       12.5000\n",
      "std       4.1833        4.1833\n",
      "min       0.0000        6.0000\n",
      "25%       3.2500        9.2500\n",
      "50%       6.5000       12.5000\n",
      "75%       9.7500       15.7500\n",
      "max      13.0000       19.0000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     14 non-null     int64  \n",
      " 1   elapsed_time  14 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 352.0 bytes\n",
      "Info for Metadata.csv (Candidate 6):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 6):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  18.000000  18.000000  18.000000  18.000000  18.000000  18.000000   \n",
      "mean    8.500000  41.342222  46.162222   0.711182   0.138992   0.149826   \n",
      "std     5.338539  26.101363  26.028482   0.198963   0.116937   0.105570   \n",
      "min     0.000000   0.000000   5.280000   0.307604   0.005599   0.011148   \n",
      "25%     4.250000  20.230000  24.480000   0.613703   0.040437   0.067492   \n",
      "50%     8.500000  41.740000  46.740000   0.689340   0.140605   0.123151   \n",
      "75%    12.750000  62.190000  66.650000   0.892071   0.183205   0.214039   \n",
      "max    17.000000  83.040000  86.760000   0.983253   0.484113   0.389255   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  18.000000  18.000000  18.000000     18.000000     18.000000  \n",
      "mean    0.679755   0.490252   0.367792      0.481433      2.583163  \n",
      "std     0.207984   0.229847   0.211848      0.314647      0.581728  \n",
      "min     0.246212   0.003024   0.017593      0.111189      0.806452  \n",
      "25%     0.568087   0.372056   0.282918      0.250644      2.465960  \n",
      "50%     0.738239   0.491895   0.356393      0.376623      2.674237  \n",
      "75%     0.836144   0.664430   0.459095      0.806500      2.982955  \n",
      "max     0.914015   0.888548   0.765156      0.977169      3.320313  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            18 non-null     int64  \n",
      " 1   start         18 non-null     float64\n",
      " 2   end           18 non-null     float64\n",
      " 3   text          18 non-null     object \n",
      " 4   positive      18 non-null     float64\n",
      " 5   negative      18 non-null     float64\n",
      " 6   neutral       18 non-null     float64\n",
      " 7   confident     18 non-null     float64\n",
      " 8   hesitant      18 non-null     float64\n",
      " 9   concise       18 non-null     float64\n",
      " 10  enthusiastic  18 non-null     float64\n",
      " 11  speech_speed  18 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.8+ KB\n",
      "Info for Transcript Data (Candidate 6):\n",
      " None\n",
      "\n",
      "Candidate 7 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 7):\n",
      "        image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count  87.000000  87.000000  8.700000e+01  87.000000  87.000000  87.000000   \n",
      "mean   43.000000   5.641183  1.507393e-01  41.652400   8.994113  23.106425   \n",
      "std    25.258662  10.851536  5.674268e-01  31.527371  24.288680  22.893766   \n",
      "min     0.000000   0.000026  1.632180e-09   0.002298   0.000115   0.000022   \n",
      "25%    21.500000   0.268764  4.342120e-04  12.554650   0.092540   5.145540   \n",
      "50%    43.000000   1.708550  8.027740e-03  34.581800   0.293205  16.238400   \n",
      "75%    64.500000   5.755515  4.025450e-02  64.482900   1.591935  35.911650   \n",
      "max    86.000000  59.135600  4.551240e+00  99.750200  99.956300  91.471200   \n",
      "\n",
      "        surprise       neutral  \n",
      "count  87.000000  8.700000e+01  \n",
      "mean    4.081041  1.637410e+01  \n",
      "std    15.613091  2.606668e+01  \n",
      "min     0.000004  7.548270e-07  \n",
      "25%     0.002647  2.398415e-01  \n",
      "50%     0.023693  3.981520e+00  \n",
      "75%     0.295826  2.081150e+01  \n",
      "max    95.021000  9.118620e+01  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87 entries, 0 to 86\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          87 non-null     object \n",
      " 1   image_seq         87 non-null     int64  \n",
      " 2   angry             87 non-null     float64\n",
      " 3   disgust           87 non-null     float64\n",
      " 4   fear              87 non-null     float64\n",
      " 5   happy             87 non-null     float64\n",
      " 6   sad               87 non-null     float64\n",
      " 7   surprise          87 non-null     float64\n",
      " 8   neutral           87 non-null     float64\n",
      " 9   dominant_emotion  87 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 7.5+ KB\n",
      "Info for Emotion.csv (Candidate 7):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 7):\n",
      "        image_seq       gaze      blink  eye_offset\n",
      "count  87.000000  87.000000  87.000000   87.000000\n",
      "mean   44.000000   0.781609   0.218391    9.456552\n",
      "std    25.258662   0.415549   0.415549   25.453533\n",
      "min     1.000000   0.000000   0.000000  -35.804300\n",
      "25%    22.500000   1.000000   0.000000   -4.131100\n",
      "50%    44.000000   1.000000   0.000000    1.372600\n",
      "75%    65.500000   1.000000   0.000000   16.909500\n",
      "max    87.000000   1.000000   1.000000   89.774500\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87 entries, 0 to 86\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    87 non-null     object \n",
      " 1   image_seq   87 non-null     int64  \n",
      " 2   gaze        87 non-null     int64  \n",
      " 3   blink       87 non-null     int64  \n",
      " 4   eye_offset  87 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.1+ KB\n",
      "Info for Gaze.csv (Candidate 7):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 7):\n",
      "        image_seq  elapsed_time\n",
      "count  51.000000     51.000000\n",
      "mean   45.274510     46.274510\n",
      "std    24.248776     24.248776\n",
      "min     1.000000      2.000000\n",
      "25%    26.000000     27.000000\n",
      "50%    48.000000     49.000000\n",
      "75%    67.500000     68.500000\n",
      "max    83.000000     84.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     51 non-null     int64  \n",
      " 1   elapsed_time  51 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 944.0 bytes\n",
      "Info for Metadata.csv (Candidate 7):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 7):\n",
      "              id      start        end   positive   negative    neutral  \\\n",
      "count  13.00000  13.000000  13.000000  13.000000  13.000000  13.000000   \n",
      "mean    6.00000  42.424615  48.996923   0.717354   0.140232   0.142414   \n",
      "std     3.89444  26.507028  25.876174   0.240184   0.155618   0.120115   \n",
      "min     0.00000   0.000000  10.080000   0.277081   0.009591   0.019422   \n",
      "25%     3.00000  21.640000  28.720000   0.579895   0.013389   0.033487   \n",
      "50%     6.00000  42.680000  49.280000   0.779631   0.077198   0.119212   \n",
      "75%     9.00000  62.560000  68.480000   0.955633   0.209222   0.202388   \n",
      "max    12.00000  84.080000  87.600000   0.967672   0.559853   0.411560   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  13.000000  13.000000  13.000000     13.000000     13.000000  \n",
      "mean    0.703714   0.457070   0.398571      0.463940      2.284897  \n",
      "std     0.147163   0.279431   0.233381      0.301260      0.469236  \n",
      "min     0.282490   0.020519   0.129945      0.121832      1.694915  \n",
      "25%     0.679421   0.265143   0.203513      0.244110      1.785714  \n",
      "50%     0.725499   0.571502   0.315587      0.331456      2.343750  \n",
      "75%     0.791392   0.610557   0.583936      0.697655      2.604167  \n",
      "max     0.866972   0.916887   0.829082      0.969768      2.954545  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            13 non-null     int64  \n",
      " 1   start         13 non-null     float64\n",
      " 2   end           13 non-null     float64\n",
      " 3   text          13 non-null     object \n",
      " 4   positive      13 non-null     float64\n",
      " 5   negative      13 non-null     float64\n",
      " 6   neutral       13 non-null     float64\n",
      " 7   confident     13 non-null     float64\n",
      " 8   hesitant      13 non-null     float64\n",
      " 9   concise       13 non-null     float64\n",
      " 10  enthusiastic  13 non-null     float64\n",
      " 11  speech_speed  13 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.3+ KB\n",
      "Info for Transcript Data (Candidate 7):\n",
      " None\n",
      "\n",
      "Candidate 8 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 8):\n",
      "        image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count  93.000000  93.000000  9.300000e+01  93.000000  93.000000  93.000000   \n",
      "mean   46.000000   8.115339  1.119884e-02  11.939264   2.120367   1.955231   \n",
      "std    26.990739  13.794058  4.575753e-02  18.479163   8.388213   3.985409   \n",
      "min     0.000000   0.025846  8.551100e-11   0.004501   0.002123   0.007992   \n",
      "25%    23.000000   0.334470  2.932250e-07   0.296672   0.052007   0.205621   \n",
      "50%    46.000000   1.440180  3.979970e-05   1.958190   0.302347   0.511124   \n",
      "75%    69.000000   8.874540  1.594090e-03  16.662700   0.776652   1.603200   \n",
      "max    92.000000  59.193800  3.162430e-01  87.632500  71.745700  28.907800   \n",
      "\n",
      "        surprise    neutral  \n",
      "count  93.000000  93.000000  \n",
      "mean    1.901795  73.956810  \n",
      "std     6.809604  32.030199  \n",
      "min     0.000016   0.791256  \n",
      "25%     0.003340  43.812200  \n",
      "50%     0.040144  92.759500  \n",
      "75%     0.550705  98.513200  \n",
      "max    58.758100  99.888500  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 93 entries, 0 to 92\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          93 non-null     object \n",
      " 1   image_seq         93 non-null     int64  \n",
      " 2   angry             93 non-null     float64\n",
      " 3   disgust           93 non-null     float64\n",
      " 4   fear              93 non-null     float64\n",
      " 5   happy             93 non-null     float64\n",
      " 6   sad               93 non-null     float64\n",
      " 7   surprise          93 non-null     float64\n",
      " 8   neutral           93 non-null     float64\n",
      " 9   dominant_emotion  93 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 8.0+ KB\n",
      "Info for Emotion.csv (Candidate 8):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 8):\n",
      "        image_seq       gaze      blink  eye_offset\n",
      "count  93.000000  93.000000  93.000000   93.000000\n",
      "mean   47.000000   0.946237   0.032258    6.564640\n",
      "std    26.990739   0.226773   0.177642   11.373373\n",
      "min     1.000000   0.000000   0.000000  -15.050100\n",
      "25%    24.000000   1.000000   0.000000    0.442100\n",
      "50%    47.000000   1.000000   0.000000    3.917300\n",
      "75%    70.000000   1.000000   0.000000    9.299900\n",
      "max    93.000000   1.000000   1.000000   69.983200\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 93 entries, 0 to 92\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    93 non-null     object \n",
      " 1   image_seq   93 non-null     int64  \n",
      " 2   gaze        93 non-null     int64  \n",
      " 3   blink       93 non-null     int64  \n",
      " 4   eye_offset  93 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.4+ KB\n",
      "Info for Gaze.csv (Candidate 8):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 8):\n",
      "        image_seq  elapsed_time\n",
      "count  93.000000     93.000000\n",
      "mean   46.000000     47.000000\n",
      "std    26.990739     26.990739\n",
      "min     0.000000      1.000000\n",
      "25%    23.000000     24.000000\n",
      "50%    46.000000     47.000000\n",
      "75%    69.000000     70.000000\n",
      "max    92.000000     93.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     93 non-null     int64  \n",
      " 1   elapsed_time  93 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.6 KB\n",
      "Info for Metadata.csv (Candidate 8):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 8):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  16.000000  16.000000  16.000000  16.000000  16.000000  16.000000   \n",
      "mean    7.500000  45.995000  51.702500   0.605402   0.192292   0.202306   \n",
      "std     4.760952  29.214206  28.541962   0.235258   0.134117   0.125727   \n",
      "min     0.000000   0.000000   6.880000   0.215706   0.031729   0.023067   \n",
      "25%     3.750000  22.160000  27.650000   0.386803   0.079141   0.108173   \n",
      "50%     7.500000  46.220000  52.840000   0.630619   0.154461   0.188653   \n",
      "75%    11.250000  70.120000  76.390000   0.808925   0.300131   0.276839   \n",
      "max    15.000000  89.840000  91.320000   0.902281   0.406963   0.498208   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  16.000000  16.000000  16.000000     16.000000     16.000000  \n",
      "mean    0.555011   0.507622   0.352011      0.437399      2.902953  \n",
      "std     0.265491   0.276555   0.209769      0.319998      0.638401  \n",
      "min     0.067931   0.071692   0.035912      0.067640      1.796407  \n",
      "25%     0.349258   0.278676   0.208833      0.138707      2.461608  \n",
      "50%     0.571599   0.492247   0.287216      0.389998      2.816024  \n",
      "75%     0.818429   0.736031   0.475020      0.654394      3.153897  \n",
      "max     0.925557   0.982899   0.744804      0.971159      4.054054  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            16 non-null     int64  \n",
      " 1   start         16 non-null     float64\n",
      " 2   end           16 non-null     float64\n",
      " 3   text          16 non-null     object \n",
      " 4   positive      16 non-null     float64\n",
      " 5   negative      16 non-null     float64\n",
      " 6   neutral       16 non-null     float64\n",
      " 7   confident     16 non-null     float64\n",
      " 8   hesitant      16 non-null     float64\n",
      " 9   concise       16 non-null     float64\n",
      " 10  enthusiastic  16 non-null     float64\n",
      " 11  speech_speed  16 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n",
      "Info for Transcript Data (Candidate 8):\n",
      " None\n",
      "\n",
      "Candidate 9 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 9):\n",
      "        image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count  86.000000  86.000000  8.600000e+01  86.000000  86.000000  86.000000   \n",
      "mean   42.500000   6.337654  1.396405e-01  18.602680  16.734190   4.293063   \n",
      "std    24.969982   7.712496  3.905607e-01  20.513298  27.389401   5.937296   \n",
      "min     0.000000   0.001452  1.465590e-07   0.013609   0.007067   0.004872   \n",
      "25%    21.250000   0.850265  3.740085e-04   2.960657   0.325851   0.601723   \n",
      "50%    42.500000   3.243240  8.396090e-03   9.066630   3.332290   1.893290   \n",
      "75%    63.750000   9.500697  9.576575e-02  27.268000  14.564825   5.768842   \n",
      "max    85.000000  46.511700  2.944570e+00  76.316400  98.331100  28.771000   \n",
      "\n",
      "        surprise    neutral  \n",
      "count  86.000000  86.000000  \n",
      "mean   15.761101  38.131673  \n",
      "std    22.198794  35.152782  \n",
      "min     0.001558   0.186039  \n",
      "25%     0.590199   7.115168  \n",
      "50%     4.469680  28.956600  \n",
      "75%    22.935025  75.421375  \n",
      "max    95.902500  99.552500  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86 entries, 0 to 85\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          86 non-null     object \n",
      " 1   image_seq         86 non-null     int64  \n",
      " 2   angry             86 non-null     float64\n",
      " 3   disgust           86 non-null     float64\n",
      " 4   fear              86 non-null     float64\n",
      " 5   happy             86 non-null     float64\n",
      " 6   sad               86 non-null     float64\n",
      " 7   surprise          86 non-null     float64\n",
      " 8   neutral           86 non-null     float64\n",
      " 9   dominant_emotion  86 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 7.4+ KB\n",
      "Info for Emotion.csv (Candidate 9):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 9):\n",
      "        image_seq       gaze      blink  eye_offset\n",
      "count  86.000000  86.000000  86.000000   86.000000\n",
      "mean   43.500000   0.965116   0.023256    8.586290\n",
      "std    24.969982   0.184561   0.151599    9.477504\n",
      "min     1.000000   0.000000   0.000000  -17.530400\n",
      "25%    22.250000   1.000000   0.000000    3.462100\n",
      "50%    43.500000   1.000000   0.000000    9.297250\n",
      "75%    64.750000   1.000000   0.000000   14.247350\n",
      "max    86.000000   1.000000   1.000000   37.400600\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86 entries, 0 to 85\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    86 non-null     object \n",
      " 1   image_seq   86 non-null     int64  \n",
      " 2   gaze        86 non-null     int64  \n",
      " 3   blink       86 non-null     int64  \n",
      " 4   eye_offset  86 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.0+ KB\n",
      "Info for Gaze.csv (Candidate 9):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 9):\n",
      "        image_seq  elapsed_time\n",
      "count  86.000000     86.000000\n",
      "mean   42.500000     43.500000\n",
      "std    24.969982     24.969982\n",
      "min     0.000000      1.000000\n",
      "25%    21.250000     22.250000\n",
      "50%    42.500000     43.500000\n",
      "75%    63.750000     64.750000\n",
      "max    85.000000     86.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86 entries, 0 to 85\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     86 non-null     int64  \n",
      " 1   elapsed_time  86 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.5 KB\n",
      "Info for Metadata.csv (Candidate 9):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 9):\n",
      "              id      start        end  positive  negative   neutral  \\\n",
      "count  9.000000   9.000000   9.000000  9.000000  9.000000  9.000000   \n",
      "mean   4.000000  28.555556  37.555556  0.617353  0.223949  0.158699   \n",
      "std    2.738613  24.264744  27.194260  0.277458  0.225380  0.094944   \n",
      "min    0.000000   0.000000   4.000000  0.066446  0.006704  0.007567   \n",
      "25%    2.000000  10.000000  16.000000  0.487809  0.121449  0.140751   \n",
      "50%    4.000000  25.000000  31.000000  0.643916  0.170376  0.148174   \n",
      "75%    6.000000  43.000000  59.000000  0.734722  0.257262  0.224349   \n",
      "max    8.000000  69.000000  81.000000  0.985729  0.762480  0.300512   \n",
      "\n",
      "       confident  hesitant   concise  enthusiastic  speech_speed  \n",
      "count   9.000000  9.000000  9.000000      9.000000      9.000000  \n",
      "mean    0.591842  0.538732  0.381809      0.505152      3.329938  \n",
      "std     0.260862  0.354912  0.262527      0.396666      0.634821  \n",
      "min     0.013361  0.027346  0.016398      0.004274      2.166667  \n",
      "25%     0.517857  0.242967  0.186974      0.246040      3.000000  \n",
      "50%     0.605490  0.658954  0.302920      0.347600      3.444444  \n",
      "75%     0.709294  0.834372  0.578688      0.947033      3.900000  \n",
      "max     0.937101  0.904767  0.725939      0.995264      4.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            9 non-null      int64  \n",
      " 1   start         9 non-null      float64\n",
      " 2   end           9 non-null      float64\n",
      " 3   text          9 non-null      object \n",
      " 4   positive      9 non-null      float64\n",
      " 5   negative      9 non-null      float64\n",
      " 6   neutral       9 non-null      float64\n",
      " 7   confident     9 non-null      float64\n",
      " 8   hesitant      9 non-null      float64\n",
      " 9   concise       9 non-null      float64\n",
      " 10  enthusiastic  9 non-null      float64\n",
      " 11  speech_speed  9 non-null      float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 992.0+ bytes\n",
      "Info for Transcript Data (Candidate 9):\n",
      " None\n",
      "\n",
      "Candidate 10 Data:\n",
      "Summary Statistics for Emotion.csv (Candidate 10):\n",
      "        image_seq      angry       disgust       fear         happy        sad  \\\n",
      "count  90.000000  90.000000  9.000000e+01  90.000000  9.000000e+01  90.000000   \n",
      "mean   45.311111   3.856539  4.845111e-02  36.143804  4.215283e+00  32.656818   \n",
      "std    26.393157   6.837119  2.822450e-01  29.611261  1.326247e+01  27.452548   \n",
      "min     0.000000   0.002080  1.680020e-14   0.005674  1.959540e-09   0.150580   \n",
      "25%    23.250000   0.246497  1.011588e-05  12.486100  8.162750e-03   7.890707   \n",
      "50%    45.500000   1.197890  3.969240e-04  30.292750  3.268370e-01  26.850100   \n",
      "75%    67.750000   4.197088  1.341535e-02  65.440375  1.797740e+00  56.829700   \n",
      "max    90.000000  45.034900  2.656160e+00  99.031300  9.745370e+01  98.333400   \n",
      "\n",
      "           surprise    neutral  \n",
      "count  9.000000e+01  90.000000  \n",
      "mean   4.330881e+00  18.748220  \n",
      "std    1.180172e+01  26.503800  \n",
      "min    4.278190e-07   0.008691  \n",
      "25%    1.008948e-02   1.391075  \n",
      "50%    1.304275e-01   7.152030  \n",
      "75%    1.926030e+00  22.284400  \n",
      "max    6.127830e+01  99.061200  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 90 entries, 0 to 89\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          90 non-null     object \n",
      " 1   image_seq         90 non-null     int64  \n",
      " 2   angry             90 non-null     float64\n",
      " 3   disgust           90 non-null     float64\n",
      " 4   fear              90 non-null     float64\n",
      " 5   happy             90 non-null     float64\n",
      " 6   sad               90 non-null     float64\n",
      " 7   surprise          90 non-null     float64\n",
      " 8   neutral           90 non-null     float64\n",
      " 9   dominant_emotion  90 non-null     object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 7.7+ KB\n",
      "Info for Emotion.csv (Candidate 10):\n",
      " None\n",
      "Summary Statistics for Gaze.csv (Candidate 10):\n",
      "        image_seq       gaze      blink  eye_offset\n",
      "count  90.000000  90.000000  90.000000   90.000000\n",
      "mean   46.311111   0.733333   0.166667   11.498590\n",
      "std    26.393157   0.444694   0.374766   17.923358\n",
      "min     1.000000   0.000000   0.000000  -24.969600\n",
      "25%    24.250000   0.000000   0.000000   -0.792775\n",
      "50%    46.500000   1.000000   0.000000    4.156950\n",
      "75%    68.750000   1.000000   0.000000   28.314000\n",
      "max    91.000000   1.000000   1.000000   56.914700\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 90 entries, 0 to 89\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   movie_id    90 non-null     object \n",
      " 1   image_seq   90 non-null     int64  \n",
      " 2   gaze        90 non-null     int64  \n",
      " 3   blink       90 non-null     int64  \n",
      " 4   eye_offset  90 non-null     float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 4.2+ KB\n",
      "Info for Gaze.csv (Candidate 10):\n",
      " None\n",
      "Summary Statistics for Metadata.csv (Candidate 10):\n",
      "        image_seq  elapsed_time\n",
      "count   91.00000     91.000000\n",
      "mean    45.00000     45.186813\n",
      "std     26.41338     26.150382\n",
      "min      0.00000      1.000000\n",
      "25%     22.50000     22.500000\n",
      "50%     45.00000     45.000000\n",
      "75%     67.50000     67.500000\n",
      "max     90.00000     90.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91 entries, 0 to 90\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   image_seq     91 non-null     int64  \n",
      " 1   elapsed_time  91 non-null     float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.5 KB\n",
      "Info for Metadata.csv (Candidate 10):\n",
      " None\n",
      "Summary Statistics for Transcript Data (Candidate 10):\n",
      "               id      start        end   positive   negative    neutral  \\\n",
      "count  17.000000  17.000000  17.000000  17.000000  17.000000  17.000000   \n",
      "mean    8.000000  43.091765  48.360000   0.589267   0.220948   0.189785   \n",
      "std     5.049752  27.237727  27.045558   0.217395   0.199494   0.086000   \n",
      "min     0.000000   0.000000   6.040000   0.042917   0.013739   0.023242   \n",
      "25%     4.000000  22.560000  26.760000   0.457349   0.094716   0.163491   \n",
      "50%     8.000000  42.320000  47.400000   0.594038   0.206400   0.199470   \n",
      "75%    12.000000  63.480000  69.160000   0.737435   0.259974   0.243070   \n",
      "max    16.000000  88.840000  89.720000   0.963019   0.879557   0.336251   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  17.000000  17.000000  17.000000     17.000000     17.000000  \n",
      "mean    0.619852   0.520637   0.385655      0.325507      3.248518  \n",
      "std     0.252520   0.236410   0.239241      0.154096      0.539271  \n",
      "min     0.127398   0.100494   0.020206      0.104140      2.571429  \n",
      "25%     0.455449   0.384795   0.221028      0.239480      2.814570  \n",
      "50%     0.732424   0.450221   0.388321      0.282800      3.169014  \n",
      "75%     0.821343   0.750270   0.604331      0.383717      3.543307  \n",
      "max     0.888680   0.881647   0.776919      0.623946      4.375000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            17 non-null     int64  \n",
      " 1   start         17 non-null     float64\n",
      " 2   end           17 non-null     float64\n",
      " 3   text          17 non-null     object \n",
      " 4   positive      17 non-null     float64\n",
      " 5   negative      17 non-null     float64\n",
      " 6   neutral       17 non-null     float64\n",
      " 7   confident     17 non-null     float64\n",
      " 8   hesitant      17 non-null     float64\n",
      " 9   concise       17 non-null     float64\n",
      " 10  enthusiastic  17 non-null     float64\n",
      " 11  speech_speed  17 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.7+ KB\n",
      "Info for Transcript Data (Candidate 10):\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Function to display describe() and info() for a DataFrame\n",
    "def describe_info(dataframe, name):\n",
    "    print(f\"Summary Statistics for {name}:\\n\", dataframe.describe())\n",
    "    print(f\"Info for {name}:\\n\", dataframe.info())\n",
    "\n",
    "# Apply describe() and info() for emotion.csv, gaze.csv, metadata.csv, and transcript_data tables\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    print(f\"\\nCandidate {folder} Data:\")\n",
    "    describe_info(emotion_dfs_no_duplicates[i], f\"Emotion.csv (Candidate {folder})\")\n",
    "    describe_info(gaze_dfs_no_duplicates[i], f\"Gaze.csv (Candidate {folder})\")\n",
    "    describe_info(metadata_dfs[i], f\"Metadata.csv (Candidate {folder})\")\n",
    "    describe_info(transcript_dfs[i], f\"Transcript Data (Candidate {folder})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f309bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified tables replaced the original tables.\n"
     ]
    }
   ],
   "source": [
    "# Replace original files with modified DataFrames\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    emotion_dfs_no_duplicates[i].to_csv(os.path.join(base_dir, 'emotion_data', folder, 'emotion.csv'), index=False)\n",
    "    gaze_dfs_no_duplicates[i].to_csv(os.path.join(base_dir, 'emotion_data', folder, 'gaze.csv'), index=False)\n",
    "    metadata_dfs[i].to_csv(os.path.join(base_dir, 'emotion_data', folder, 'metadata.csv'), index=False)\n",
    "    transcript_dfs[i].to_csv(os.path.join(base_dir, 'transcript_data', f'{folder}.csv'), index=False)\n",
    "\n",
    "print(\"Modified tables replaced the original tables.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce830e",
   "metadata": {},
   "source": [
    "Merge emotion.csv, gaze.csv and metadata.csv to form merged_emotion_i.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf58623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Emotion Data - Candidate 1:\n",
      "                                movie_id  image_seq     angry   disgust  \\\n",
      "0  93663f94-bf0a-4ce8-a29a-a5236cc7fe6a          6   6.41279  0.000239   \n",
      "1  93663f94-bf0a-4ce8-a29a-a5236cc7fe6a          7  29.81320  1.365940   \n",
      "\n",
      "       fear     happy       sad  surprise  neutral dominant_emotion  gaze  \\\n",
      "0   4.53791  0.134349   3.56569  0.555717  84.7933          neutral     0   \n",
      "1  31.50510  5.555130  11.35700  2.189640  18.2140             fear     1   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      0     26.8643           7.0  \n",
      "1      0      1.9027           8.0  \n",
      "Merged Emotion Data - Candidate 2:\n",
      "                                movie_id  image_seq      angry   disgust  \\\n",
      "0  baa26895-85b2-465b-a972-649b41d9870e          1   0.179621  0.000185   \n",
      "1  baa26895-85b2-465b-a972-649b41d9870e          2  10.126300  0.087004   \n",
      "\n",
      "       fear    happy       sad   surprise   neutral dominant_emotion  gaze  \\\n",
      "0  0.055258  93.5664   6.18999   0.001184  0.007402            happy     0   \n",
      "1  6.057070  42.7038  19.81920  15.360900  5.845700            happy     0   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      1     42.3816           2.0  \n",
      "1      0     28.1727           3.0  \n",
      "Merged Emotion Data - Candidate 3:\n",
      "                                movie_id  image_seq     angry       disgust  \\\n",
      "0  d0b9170b-98b9-48e1-a1b2-1d661bb0d853          1  0.016925  1.391500e-07   \n",
      "1  d0b9170b-98b9-48e1-a1b2-1d661bb0d853          2  0.095944  2.349850e-06   \n",
      "\n",
      "      fear     happy       sad  surprise   neutral dominant_emotion  gaze  \\\n",
      "0  63.5732  28.61190   1.63691  0.569473   5.59155             fear     0   \n",
      "1  35.4845   9.79849  13.52990  8.988050  32.10300             fear     0   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      1     72.7051           2.0  \n",
      "1      0     32.5648           3.0  \n",
      "Merged Emotion Data - Candidate 4:\n",
      "                                movie_id  image_seq     angry       disgust  \\\n",
      "0  6b0386fc-41de-4196-b0d6-3d0b815c2dbc          1  0.273406  2.415080e-06   \n",
      "1  6b0386fc-41de-4196-b0d6-3d0b815c2dbc          2  0.087041  2.285780e-10   \n",
      "\n",
      "       fear     happy       sad  surprise  neutral dominant_emotion  gaze  \\\n",
      "0  0.046480  0.113288  0.156266  0.022630  99.3879          neutral     1   \n",
      "1  0.025851  0.000082  0.186978  0.002026  99.6980          neutral     0   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      0      6.7544           2.0  \n",
      "1      1     44.2002           3.0  \n",
      "Merged Emotion Data - Candidate 5:\n",
      "                                movie_id  image_seq     angry       disgust  \\\n",
      "0  9c350343-e895-49df-af90-d50b91d19d3e          1  0.105126  2.913510e-11   \n",
      "1  9c350343-e895-49df-af90-d50b91d19d3e          2  0.032465  4.927800e-11   \n",
      "\n",
      "       fear     happy       sad  surprise  neutral dominant_emotion  gaze  \\\n",
      "0  0.000546  0.004444  0.020332  0.000050  99.8695          neutral     1   \n",
      "1  0.000134  0.326047  0.076447  0.000012  99.5649          neutral     1   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      1    -16.9749          13.0  \n",
      "1      0    -22.6020          49.0  \n",
      "Merged Emotion Data - Candidate 6:\n",
      "                                movie_id  image_seq     angry       disgust  \\\n",
      "0  92016995-e455-4651-9f6e-fbca0d423f21          1  0.001332  1.421510e-07   \n",
      "1  92016995-e455-4651-9f6e-fbca0d423f21          2  0.001311  1.414390e-07   \n",
      "\n",
      "       fear    happy       sad  surprise  neutral dominant_emotion  gaze  \\\n",
      "0  0.013304  36.9452  0.179674  0.008271  62.8523          neutral     1   \n",
      "1  0.013234  37.1393  0.178144  0.008264  62.6598          neutral     1   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      0     -1.8621           7.0  \n",
      "1      0     -1.5986           8.0  \n",
      "Merged Emotion Data - Candidate 7:\n",
      "                                movie_id  image_seq     angry   disgust  \\\n",
      "0  6539370c-256e-4ed2-9d00-1be1f051163f          1  6.587830  0.020338   \n",
      "1  6539370c-256e-4ed2-9d00-1be1f051163f          3  0.000539  0.000017   \n",
      "\n",
      "        fear      happy        sad  surprise  neutral dominant_emotion  gaze  \\\n",
      "0  35.106600   0.103848  38.967200  0.001294  19.2129              sad     1   \n",
      "1   0.041162  99.408400   0.239465  0.067905   0.2425            happy     1   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      1     11.9221           2.0  \n",
      "1      0      3.0297           4.0  \n",
      "Merged Emotion Data - Candidate 8:\n",
      "                                movie_id  image_seq     angry   disgust  \\\n",
      "0  813af424-a584-4417-b7ee-0d4c705e83c9          1  0.840043  0.000092   \n",
      "1  813af424-a584-4417-b7ee-0d4c705e83c9          2  2.290200  0.000181   \n",
      "\n",
      "      fear     happy       sad  surprise  neutral dominant_emotion  gaze  \\\n",
      "0  2.24265  0.560995  0.417769  0.022157  95.9163          neutral     1   \n",
      "1  5.73170  0.132673  3.990380  0.011224  87.8436          neutral     1   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      0      1.7394           2.0  \n",
      "1      0     -1.0581           3.0  \n",
      "Merged Emotion Data - Candidate 9:\n",
      "                                movie_id  image_seq    angry   disgust  \\\n",
      "0  dfb0d746-609f-4dac-8e1d-c0325fb64394          1  2.08114  0.293596   \n",
      "1  dfb0d746-609f-4dac-8e1d-c0325fb64394          2  9.43836  0.460568   \n",
      "\n",
      "      fear    happy      sad  surprise   neutral dominant_emotion  gaze  \\\n",
      "0  7.37185  76.1906  1.52434   7.60248  4.936020            happy     1   \n",
      "1  9.06742  71.4096  3.41275   5.92206  0.289199            happy     1   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      0    -15.4688           2.0  \n",
      "1      0      4.3447           3.0  \n",
      "Merged Emotion Data - Candidate 10:\n",
      "                                movie_id  image_seq     angry   disgust  \\\n",
      "0  83c20b83-7881-499d-a40d-cc06b65869f8          1  0.099217  0.029228   \n",
      "1  83c20b83-7881-499d-a40d-cc06b65869f8          2  0.430551  0.000310   \n",
      "\n",
      "       fear      happy       sad   surprise   neutral dominant_emotion  gaze  \\\n",
      "0   1.27949  97.453700  0.837835   0.002792  0.297701            happy     1   \n",
      "1  43.12370   0.283289  0.202208  55.544700  0.415176         surprise     0   \n",
      "\n",
      "   blink  eye_offset  elapsed_time  \n",
      "0      1      5.3099           2.0  \n",
      "1      1     47.5657           3.0  \n"
     ]
    }
   ],
   "source": [
    "# Create a new folder for merged emotion data if it doesn't exist\n",
    "merged_emotion_dir = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\\merged_emotion\"\n",
    "os.makedirs(merged_emotion_dir, exist_ok=True)\n",
    "\n",
    "# Create empty lists to store merged DataFrames\n",
    "merged_emotion_dfs = []\n",
    "\n",
    "# Loop through candidate folders\n",
    "for folder in candidate_folders:\n",
    "    gaze_path = os.path.join(base_dir, 'emotion_data', folder, 'gaze.csv')\n",
    "\n",
    "    # Read gaze.csv and remove \"movie_id\" column\n",
    "    gaze_df = pd.read_csv(gaze_path)\n",
    "    gaze_df = gaze_df.drop(columns=['movie_id'])\n",
    "\n",
    "    # Read emotion.csv and metadata.csv\n",
    "    emotion_df = emotion_dfs_no_duplicates[int(folder) - 1]\n",
    "    metadata_df = metadata_dfs[int(folder) - 1]\n",
    "\n",
    "    # Merge emotion.csv, gaze.csv, and metadata.csv based on \"image_seq\"\n",
    "    merged_df = pd.merge(emotion_df, gaze_df, on='image_seq')\n",
    "    merged_df = pd.merge(merged_df, metadata_df, on='image_seq')\n",
    "\n",
    "    # Save the merged DataFrame as merged_emotion_i.csv\n",
    "    merged_filename = os.path.join(merged_emotion_dir, f'merged_emotion_{folder}.csv')\n",
    "    merged_df.to_csv(merged_filename, index=False)\n",
    "\n",
    "    # Append the merged DataFrame to the list\n",
    "    merged_emotion_dfs.append(merged_df)\n",
    "\n",
    "    # Display the first two rows of the merged DataFrame\n",
    "    print(f\"Merged Emotion Data - Candidate {folder}:\\n\", merged_df.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ac731",
   "metadata": {},
   "source": [
    "Consolidating time intervals and eliminating gaps in the transcript_data tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1bb9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No modifications needed for Transcript Data - Candidate 1.\n",
      "Modified Transcript Data - Candidate 2:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00   4.32   Hello, I am Beside You. I am Cameron Barajas ...   \n",
      "1   1   4.32  10.00   today. I recently completed my BBA in 2022. I...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.909206  0.015431  0.075362   0.976302  0.020649  0.849303      0.998064   \n",
      "1  0.660675  0.052640  0.286685   0.968629  0.741091  0.649625      0.701379   \n",
      "\n",
      "   speech_speed  \n",
      "0      4.166667  \n",
      "1      2.992958  \n",
      "No modifications needed for Transcript Data - Candidate 3.\n",
      "No modifications needed for Transcript Data - Candidate 4.\n",
      "No modifications needed for Transcript Data - Candidate 5.\n",
      "Modified Transcript Data - Candidate 6:\n",
      "    id  start   end                                               text  \\\n",
      "0   0   0.00  5.28   Hi, my name is Nathan Lewis. I'm a first year...   \n",
      "1   1   5.28  9.40   Kashipur. From having a consulting experience...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.442265  0.168479  0.389255   0.814687  0.888548  0.687718      0.475202   \n",
      "1  0.625293  0.189070  0.185637   0.882211  0.733979  0.715336      0.498379   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.840909  \n",
      "1      2.669903  \n",
      "Modified Transcript Data - Candidate 7:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00  10.08   Hello, I am Joseph Nichols. I belong to the h...   \n",
      "1   1  10.08  16.40   in earth science from Banaras Hindu Universit...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.520804  0.168075  0.311122   0.844285  0.916887  0.674078      0.697655   \n",
      "1  0.357795  0.230645  0.411560   0.612985  0.800743  0.438345      0.301149   \n",
      "\n",
      "   speech_speed  \n",
      "0      1.785714  \n",
      "1      2.531646  \n",
      "Modified Transcript Data - Candidate 8:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00   6.88   Hi, hope you're doing well. I'm Srivats Biyan...   \n",
      "1   1   6.88  12.12   Now before joining IIM Co-Ecode, what all hav...   \n",
      "\n",
      "   positive  negative  neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.749869  0.073202  0.17693   0.613489  0.810735  0.677798      0.614666   \n",
      "1  0.250922  0.367668  0.38141   0.156975  0.982899  0.177705      0.087839   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.470930  \n",
      "1      3.053435  \n",
      "No modifications needed for Transcript Data - Candidate 9.\n",
      "Modified Transcript Data - Candidate 10:\n",
      "    id  start    end                                               text  \\\n",
      "0   0   0.00   6.04   My name is Michael Ramos, I am from Patna, Bi...   \n",
      "1   1   6.04  12.08   I went up to do my graduation in B.Com Honour...   \n",
      "\n",
      "   positive  negative   neutral  confident  hesitant   concise  enthusiastic  \\\n",
      "0  0.457349  0.206400  0.336251   0.888680  0.881647  0.705780      0.623946   \n",
      "1  0.532671  0.222764  0.244564   0.732424  0.750270  0.620743      0.367078   \n",
      "\n",
      "   speech_speed  \n",
      "0      2.980132  \n",
      "1      2.814570  \n",
      "Updated transcript data saved.\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store modified DataFrames for transcript data\n",
    "transcript_dfs_updated = []\n",
    "\n",
    "# Loop through candidate folders\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    transcript_path = os.path.join(base_dir, 'transcript_data', f'{folder}.csv')\n",
    "\n",
    "    # Read transcript_data\n",
    "    transcript_df = pd.read_csv(transcript_path)\n",
    "\n",
    "    # Initialize a flag to keep track of modifications\n",
    "    modified = False\n",
    "\n",
    "    # Loop through rows to check and update values\n",
    "    for row in range(1, len(transcript_df)):\n",
    "        prev_end = transcript_df.loc[row - 1, 'end']\n",
    "        current_start = transcript_df.loc[row, 'start']\n",
    "\n",
    "        # Check if \"end\" of (i-1)th row is not equal to \"start\" of (i)th row\n",
    "        if prev_end != current_start:\n",
    "            # Calculate the average of previous values\n",
    "            avg_value = (prev_end + current_start) / 2.0\n",
    "\n",
    "            # Update \"end\" of (i-1)th row and \"start\" of (i)th row\n",
    "            transcript_df.loc[row - 1, 'end'] = avg_value\n",
    "            transcript_df.loc[row, 'start'] = avg_value\n",
    "\n",
    "            # Set the modified flag\n",
    "            modified = True\n",
    "\n",
    "    # Append the modified DataFrame to the list\n",
    "    transcript_dfs_updated.append(transcript_df)\n",
    "\n",
    "    # Display a message if modifications were made\n",
    "    if modified:\n",
    "        print(f\"Modified Transcript Data - Candidate {folder}:\\n\", transcript_df.head(2))\n",
    "    else:\n",
    "        print(f\"No modifications needed for Transcript Data - Candidate {folder}.\")\n",
    "\n",
    "# Save the updated transcript data to files\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    updated_transcript_path = os.path.join(base_dir, 'transcript_data', f'{folder}_updated.csv')\n",
    "    transcript_dfs_updated[i].to_csv(updated_transcript_path, index=False)\n",
    "\n",
    "print(\"Updated transcript data saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae272a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted original transcript file for Candidate 1.\n",
      "Deleted original transcript file for Candidate 2.\n",
      "Deleted original transcript file for Candidate 3.\n",
      "Deleted original transcript file for Candidate 4.\n",
      "Deleted original transcript file for Candidate 5.\n",
      "Deleted original transcript file for Candidate 6.\n",
      "Deleted original transcript file for Candidate 7.\n",
      "Deleted original transcript file for Candidate 8.\n",
      "Deleted original transcript file for Candidate 9.\n",
      "Deleted original transcript file for Candidate 10.\n"
     ]
    }
   ],
   "source": [
    "# Delete the original \"i.csv\" files in transcript_data folder\n",
    "for i in range(1, 11):\n",
    "    original_transcript_path = os.path.join(base_dir, 'transcript_data', f'{i}.csv')\n",
    "    \n",
    "    # Check if the file exists and delete it\n",
    "    if os.path.exists(original_transcript_path):\n",
    "        os.remove(original_transcript_path)\n",
    "        print(f\"Deleted original transcript file for Candidate {i}.\")\n",
    "    else:\n",
    "        print(f\"Original transcript file for Candidate {i} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668c13be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified transcript file for Candidate 1 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 2 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 3 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 4 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 5 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 6 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 7 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 8 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 9 saved and last 'end' value rounded off.\n",
      "Modified transcript file for Candidate 10 saved and last 'end' value rounded off.\n",
      "Rounding off and replacing completed.\n"
     ]
    }
   ],
   "source": [
    "# Function to round off the last row's \"end\" column to the upper integer value\n",
    "def round_last_end_to_integer(dataframe):\n",
    "    last_row_index = len(dataframe) - 1\n",
    "    dataframe.loc[last_row_index, 'end'] = int(dataframe.loc[last_row_index, 'end'] + 0.5)\n",
    "\n",
    "# Loop through candidate folders to round off and replace \"i_updated.csv\" files\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    updated_transcript_path = os.path.join(base_dir, 'transcript_data', f'{folder}_updated.csv')\n",
    "    \n",
    "    if os.path.exists(updated_transcript_path):\n",
    "        # Read the updated transcript data\n",
    "        updated_transcript_df = pd.read_csv(updated_transcript_path)\n",
    "        \n",
    "        # Round off the last row's \"end\" column to the upper integer value\n",
    "        round_last_end_to_integer(updated_transcript_df)\n",
    "        \n",
    "        # Save the modified transcript data, replacing the original \"i_updated.csv\" file\n",
    "        updated_transcript_df.to_csv(updated_transcript_path, index=False)\n",
    "        print(f\"Modified transcript file for Candidate {folder} saved and last 'end' value rounded off.\")\n",
    "    else:\n",
    "        print(f\"Updated transcript file for Candidate {folder} not found.\")\n",
    "\n",
    "print(\"Rounding off and replacing completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2429c2",
   "metadata": {},
   "source": [
    "merged_emotion tables are merged with the transcript_data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da030a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved for Candidate 1 in overall_data_1.csv.\n",
      "Merged data saved for Candidate 2 in overall_data_2.csv.\n",
      "Merged data saved for Candidate 3 in overall_data_3.csv.\n",
      "Merged data saved for Candidate 4 in overall_data_4.csv.\n",
      "Merged data saved for Candidate 5 in overall_data_5.csv.\n",
      "Merged data saved for Candidate 6 in overall_data_6.csv.\n",
      "Merged data saved for Candidate 7 in overall_data_7.csv.\n",
      "Merged data saved for Candidate 8 in overall_data_8.csv.\n",
      "Merged data saved for Candidate 9 in overall_data_9.csv.\n",
      "Merged data saved for Candidate 10 in overall_data_10.csv.\n",
      "Merging and saving completed.\n"
     ]
    }
   ],
   "source": [
    "# Create a new folder for overall data if it doesn't exist\n",
    "overall_data_dir = os.path.join(base_dir, 'overall_data')\n",
    "os.makedirs(overall_data_dir, exist_ok=True)\n",
    "\n",
    "# Loop through candidate folders\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    # Read merged_emotion_i.csv and i_updated.csv\n",
    "    merged_emotion_path = os.path.join(base_dir, 'merged_emotion', f'merged_emotion_{folder}.csv')\n",
    "    updated_transcript_path = os.path.join(base_dir, 'transcript_data', f'{folder}_updated.csv')\n",
    "\n",
    "    if os.path.exists(merged_emotion_path) and os.path.exists(updated_transcript_path):\n",
    "        # Read merged_emotion_i.csv and i_updated.csv\n",
    "        merged_emotion_df = pd.read_csv(merged_emotion_path)\n",
    "        updated_transcript_df = pd.read_csv(updated_transcript_path)\n",
    "\n",
    "        # Initialize lists to store rows for the merged table\n",
    "        merged_rows = []\n",
    "\n",
    "        # Loop through rows in updated_transcript_df\n",
    "        for index, row in updated_transcript_df.iterrows():\n",
    "            # Extract the start and end times from the current row\n",
    "            start_time = row['start']\n",
    "            end_time = row['end']\n",
    "\n",
    "            # Filter rows in merged_emotion_df based on elapsed_time within the range\n",
    "            filtered_rows = merged_emotion_df[\n",
    "                (merged_emotion_df['elapsed_time'] >= start_time) &\n",
    "                (merged_emotion_df['elapsed_time'] <= end_time)\n",
    "            ]\n",
    "\n",
    "            # If there are matching rows in merged_emotion_df, calculate averages\n",
    "            if not filtered_rows.empty:\n",
    "                avg_row = filtered_rows.mean(numeric_only=True)\n",
    "                avg_row['start'] = start_time\n",
    "                avg_row['end'] = end_time\n",
    "                merged_rows.append(avg_row)\n",
    "\n",
    "        # Create the merged DataFrame for the candidate\n",
    "        candidate_merged_df = pd.DataFrame(merged_rows)\n",
    "\n",
    "        # Set 'movie_id' to the value from the first row of merged_emotion_i.csv\n",
    "        candidate_merged_df['movie_id'] = merged_emotion_df['movie_id'].iloc[0]\n",
    "\n",
    "        # Remove 'image_seq' and 'elapsed_time' columns\n",
    "        candidate_merged_df = candidate_merged_df.drop(columns=['image_seq', 'elapsed_time'])\n",
    "\n",
    "        # Reorder columns to match the desired order\n",
    "        column_order = ['movie_id', 'start', 'end', 'angry', 'disgust', 'fear', 'happy', 'sad',\n",
    "                        'surprise', 'neutral', 'gaze', 'blink', 'eye_offset']\n",
    "        candidate_merged_df = candidate_merged_df[column_order]\n",
    "\n",
    "        # Save the merged DataFrame as overall_data_i.csv\n",
    "        overall_data_path = os.path.join(overall_data_dir, f'overall_data_{folder}.csv')\n",
    "        candidate_merged_df.to_csv(overall_data_path, index=False)\n",
    "\n",
    "        print(f\"Merged data saved for Candidate {folder} in overall_data_{folder}.csv.\")\n",
    "    else:\n",
    "        print(f\"Files not found for Candidate {folder}. Skipping.\")\n",
    "\n",
    "print(\"Merging and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f3c1d",
   "metadata": {},
   "source": [
    "\"dominant_emotion\" and \"subsequent_emotion\" columns are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a393f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 1.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 2.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 3.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 4.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 5.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 6.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 7.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 8.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 9.\n",
      "Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate 10.\n",
      "Adding columns completed.\n"
     ]
    }
   ],
   "source": [
    "# Loop through candidate folders\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    # Read the overall_data_i.csv file\n",
    "    overall_data_path = os.path.join(overall_data_dir, f'overall_data_{folder}.csv')\n",
    "\n",
    "    if os.path.exists(overall_data_path):\n",
    "        # Read the overall data\n",
    "        overall_data_df = pd.read_csv(overall_data_path)\n",
    "\n",
    "        # List of emotion columns\n",
    "        emotion_columns = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "        # Find the dominant and subsequent emotions for each row\n",
    "        dominant_emotions = []\n",
    "        subsequent_emotions = []\n",
    "\n",
    "        for index, row in overall_data_df.iterrows():\n",
    "            # Find the column with the maximum value (dominant emotion)\n",
    "            max_emotion = max(row[emotion_columns])\n",
    "            dominant_emotion = [col for col in emotion_columns if row[col] == max_emotion][0]\n",
    "\n",
    "            # Find the column with the second maximum value (subsequent emotion)\n",
    "            row[dominant_emotion] = 0  # Set the dominant emotion value to 0\n",
    "            second_max_emotion = max(row[emotion_columns])\n",
    "            subsequent_emotion = [col for col in emotion_columns if row[col] == second_max_emotion][0]\n",
    "\n",
    "            dominant_emotions.append(dominant_emotion)\n",
    "            subsequent_emotions.append(subsequent_emotion)\n",
    "\n",
    "        # Add \"dominant_emotion\" and \"subsequent_emotion\" columns\n",
    "        overall_data_df['dominant_emotion'] = dominant_emotions\n",
    "        overall_data_df['subsequent_emotion'] = subsequent_emotions\n",
    "\n",
    "        # Save the modified DataFrame\n",
    "        overall_data_df.to_csv(overall_data_path, index=False)\n",
    "\n",
    "        print(f\"Added 'dominant_emotion' and 'subsequent_emotion' columns for Candidate {folder}.\")\n",
    "    else:\n",
    "        print(f\"File not found for Candidate {folder}. Skipping.\")\n",
    "\n",
    "print(\"Adding columns completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd90ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved and updated for Candidate 1 in overall_data_1.csv.\n",
      "Merged data saved and updated for Candidate 2 in overall_data_2.csv.\n",
      "Merged data saved and updated for Candidate 3 in overall_data_3.csv.\n",
      "Merged data saved and updated for Candidate 4 in overall_data_4.csv.\n",
      "Merged data saved and updated for Candidate 5 in overall_data_5.csv.\n",
      "Merged data saved and updated for Candidate 6 in overall_data_6.csv.\n",
      "Merged data saved and updated for Candidate 7 in overall_data_7.csv.\n",
      "Merged data saved and updated for Candidate 8 in overall_data_8.csv.\n",
      "Merged data saved and updated for Candidate 9 in overall_data_9.csv.\n",
      "Merged data saved and updated for Candidate 10 in overall_data_10.csv.\n",
      "Merging and updating completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base directory path\n",
    "base_dir = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\"\n",
    "\n",
    "# List of candidate folders (assuming they are named '1', '2', ..., '10')\n",
    "candidate_folders = [str(i) for i in range(1, 11)]\n",
    "\n",
    "# Create a new folder for overall data if it doesn't exist\n",
    "overall_data_dir = os.path.join(base_dir, 'overall_data')\n",
    "os.makedirs(overall_data_dir, exist_ok=True)\n",
    "\n",
    "# Loop through candidate folders\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    # Read the overall_data_i.csv and i_updated.csv files\n",
    "    overall_data_path = os.path.join(overall_data_dir, f'overall_data_{folder}.csv')\n",
    "    updated_transcript_path = os.path.join(base_dir, 'transcript_data', f'{folder}_updated.csv')\n",
    "\n",
    "    if os.path.exists(overall_data_path) and os.path.exists(updated_transcript_path):\n",
    "        # Read the overall data and updated transcript data\n",
    "        overall_data_df = pd.read_csv(overall_data_path)\n",
    "        updated_transcript_df = pd.read_csv(updated_transcript_path)\n",
    "\n",
    "        # Create a set of unique \"start\" values from the updated transcript data\n",
    "        unique_start_values = set(updated_transcript_df['start'])\n",
    "\n",
    "        # Create a DataFrame to store merged rows\n",
    "        merged_rows = []\n",
    "\n",
    "        # Iterate through unique \"start\" values\n",
    "        for start_value in unique_start_values:\n",
    "            # Check if the \"start\" value is missing in overall_data_df\n",
    "            if start_value not in overall_data_df['start'].values:\n",
    "                # Create a new row with null values in all columns of overall_data_df\n",
    "                new_row = {col: None for col in overall_data_df.columns}\n",
    "\n",
    "                # Set the \"start\" value in the new row\n",
    "                new_row['start'] = start_value\n",
    "\n",
    "                # Append the new row to merged_rows\n",
    "                merged_rows.append(new_row)\n",
    "\n",
    "        # Convert merged_rows to a DataFrame\n",
    "        new_rows_df = pd.DataFrame(merged_rows)\n",
    "\n",
    "        # Concatenate overall_data_df and new_rows_df using pandas.concat\n",
    "        overall_data_df = pd.concat([overall_data_df, new_rows_df], ignore_index=True)\n",
    "\n",
    "        # Merge overall_data_df and updated_transcript_df based on the \"start\" column\n",
    "        merged_df = pd.merge(overall_data_df, updated_transcript_df, on='start', how='left')\n",
    "\n",
    "        # Sort rows in ascending order of \"start\" values\n",
    "        merged_df = merged_df.sort_values(by='start', ascending=True)\n",
    "\n",
    "        # Remove the \"id\" column\n",
    "        merged_df = merged_df.drop(columns=['id'])\n",
    "\n",
    "        # Keep the \"end\" column from updated_transcript_df\n",
    "        merged_df['end'] = updated_transcript_df['end']\n",
    "\n",
    "        # Save the merged DataFrame to the overall_data_i.csv file\n",
    "        merged_df.to_csv(overall_data_path, index=False)\n",
    "\n",
    "        print(f\"Merged data saved and updated for Candidate {folder} in overall_data_{folder}.csv.\")\n",
    "    else:\n",
    "        print(f\"Files not found for Candidate {folder}. Skipping.\")\n",
    "\n",
    "print(\"Merging and updating completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3c9926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated overall_data_1.csv for Candidate 1.\n",
      "Updated overall_data_2.csv for Candidate 2.\n",
      "Updated overall_data_3.csv for Candidate 3.\n",
      "Updated overall_data_4.csv for Candidate 4.\n",
      "Updated overall_data_5.csv for Candidate 5.\n",
      "Updated overall_data_6.csv for Candidate 6.\n",
      "Updated overall_data_7.csv for Candidate 7.\n",
      "Updated overall_data_8.csv for Candidate 8.\n",
      "Updated overall_data_9.csv for Candidate 9.\n",
      "Updated overall_data_10.csv for Candidate 10.\n",
      "Updating completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base directory path\n",
    "base_dir = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\"\n",
    "\n",
    "# List of candidate folders (assuming they are named '1', '2', ..., '10')\n",
    "candidate_folders = [str(i) for i in range(1, 11)]\n",
    "\n",
    "# Loop through candidate folders\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    # Read the overall_data_i.csv file\n",
    "    overall_data_path = os.path.join(overall_data_dir, f'overall_data_{folder}.csv')\n",
    "\n",
    "    if os.path.exists(overall_data_path):\n",
    "        # Read the overall data\n",
    "        overall_data_df = pd.read_csv(overall_data_path)\n",
    "\n",
    "        # Replace values in \"end_x\" column with \"end_y\" column values\n",
    "        overall_data_df['end_x'] = overall_data_df['end_y']\n",
    "\n",
    "        # Remove the \"end_y\" column\n",
    "        overall_data_df = overall_data_df.drop(columns=['end_y'])\n",
    "\n",
    "        # Replace missing values in \"movie_id\" column with a value from any other row\n",
    "        movie_id_values = overall_data_df['movie_id'].dropna().values\n",
    "        overall_data_df['movie_id'] = overall_data_df['movie_id'].fillna(movie_id_values[0])\n",
    "\n",
    "        # Save the updated DataFrame back to the overall_data_i.csv file\n",
    "        overall_data_df.to_csv(overall_data_path, index=False)\n",
    "\n",
    "        print(f\"Updated overall_data_{folder}.csv for Candidate {folder}.\")\n",
    "    else:\n",
    "        print(f\"File not found for Candidate {folder}. Skipping.\")\n",
    "\n",
    "print(\"Updating completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43139799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated overall_data_1.csv for Candidate 1.\n",
      "Updated overall_data_2.csv for Candidate 2.\n",
      "Updated overall_data_3.csv for Candidate 3.\n",
      "Updated overall_data_4.csv for Candidate 4.\n",
      "Updated overall_data_5.csv for Candidate 5.\n",
      "Updated overall_data_6.csv for Candidate 6.\n",
      "Updated overall_data_7.csv for Candidate 7.\n",
      "Updated overall_data_8.csv for Candidate 8.\n",
      "Updated overall_data_9.csv for Candidate 9.\n",
      "Updated overall_data_10.csv for Candidate 10.\n",
      "Updating completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base directory path\n",
    "base_dir = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\"\n",
    "\n",
    "# List of candidate folders (assuming they are named '1', '2', ..., '10')\n",
    "candidate_folders = [str(i) for i in range(1, 11)]\n",
    "\n",
    "# Loop through candidate folders\n",
    "for i, folder in enumerate(candidate_folders):\n",
    "    # Read the overall_data_i.csv file\n",
    "    overall_data_path = os.path.join(overall_data_dir, f'overall_data_{folder}.csv')\n",
    "\n",
    "    if os.path.exists(overall_data_path):\n",
    "        # Read the overall data\n",
    "        overall_data_df = pd.read_csv(overall_data_path)\n",
    "\n",
    "        # Remove the \"end\" column\n",
    "        overall_data_df = overall_data_df.drop(columns=['end'])\n",
    "\n",
    "        # Rename \"end_x\" column as \"end\"\n",
    "        overall_data_df = overall_data_df.rename(columns={'end_x': 'end'})\n",
    "\n",
    "        # Rename \"neutral_x\" column as \"neutral_emotion\"\n",
    "        overall_data_df = overall_data_df.rename(columns={'neutral_x': 'neutral_emotion'})\n",
    "\n",
    "        # Rename \"neutral_y\" column as \"neutral_sentiment\"\n",
    "        overall_data_df = overall_data_df.rename(columns={'neutral_y': 'neutral_sentiment'})\n",
    "\n",
    "        # Save the updated DataFrame back to the overall_data_i.csv file\n",
    "        overall_data_df.to_csv(overall_data_path, index=False)\n",
    "\n",
    "        print(f\"Updated overall_data_{folder}.csv for Candidate {folder}.\")\n",
    "    else:\n",
    "        print(f\"File not found for Candidate {folder}. Skipping.\")\n",
    "\n",
    "print(\"Updating completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc1aef",
   "metadata": {},
   "source": [
    "Information and Description of overall_data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84045af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Information for merged_emotion_1.csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27 entries, 0 to 26\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   movie_id          27 non-null     object \n",
      " 1   image_seq         27 non-null     int64  \n",
      " 2   angry             27 non-null     float64\n",
      " 3   disgust           27 non-null     float64\n",
      " 4   fear              27 non-null     float64\n",
      " 5   happy             27 non-null     float64\n",
      " 6   sad               27 non-null     float64\n",
      " 7   surprise          27 non-null     float64\n",
      " 8   neutral           27 non-null     float64\n",
      " 9   dominant_emotion  27 non-null     object \n",
      " 10  gaze              27 non-null     int64  \n",
      " 11  blink             27 non-null     int64  \n",
      " 12  eye_offset        27 non-null     float64\n",
      " 13  elapsed_time      27 non-null     float64\n",
      "dtypes: float64(9), int64(3), object(2)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics for merged_emotion_1.csv:\n",
      "       image_seq      angry       disgust       fear      happy        sad  \\\n",
      "count  27.000000  27.000000  2.700000e+01  27.000000  27.000000  27.000000   \n",
      "mean   41.111111  12.977268  1.077835e-01  16.048912   8.201584   7.403436   \n",
      "std    26.172994  18.379496  2.685042e-01  23.319916  14.773024   5.296560   \n",
      "min     6.000000   0.164384  7.052030e-09   0.307663   0.004353   0.176336   \n",
      "25%    18.500000   2.082490  8.978205e-05   1.822170   0.230871   3.836045   \n",
      "50%    39.000000   5.330160  2.164300e-03   4.499930   3.318960   5.278830   \n",
      "75%    62.500000  12.248150  1.203200e-01  17.063750   7.806755  10.903950   \n",
      "max    91.000000  71.172500  1.365940e+00  71.401800  66.222300  18.678900   \n",
      "\n",
      "        surprise    neutral       gaze  blink  eye_offset  elapsed_time  \n",
      "count  27.000000  27.000000  27.000000   27.0   27.000000     27.000000  \n",
      "mean    5.149664  50.111353   0.518519    0.0   16.513622     40.888889  \n",
      "std    10.734585  33.882285   0.509175    0.0   20.537270     24.639451  \n",
      "min     0.003048   2.708640   0.000000    0.0  -33.465500      7.000000  \n",
      "25%     0.189184  15.230600   0.000000    0.0   -0.042200     19.000000  \n",
      "50%     0.970922  66.257300   1.000000    0.0   19.578700     40.000000  \n",
      "75%     3.700525  79.144900   1.000000    0.0   31.233850     61.500000  \n",
      "max    50.730800  97.823000   1.000000    0.0   53.829700     86.000000  \n",
      "\n",
      "Table Information for 1_updated.csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            18 non-null     int64  \n",
      " 1   start         18 non-null     float64\n",
      " 2   end           18 non-null     float64\n",
      " 3   text          18 non-null     object \n",
      " 4   positive      18 non-null     float64\n",
      " 5   negative      18 non-null     float64\n",
      " 6   neutral       18 non-null     float64\n",
      " 7   confident     18 non-null     float64\n",
      " 8   hesitant      18 non-null     float64\n",
      " 9   concise       18 non-null     float64\n",
      " 10  enthusiastic  18 non-null     float64\n",
      " 11  speech_speed  18 non-null     float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 1.8+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics for 1_updated.csv:\n",
      "              id      start        end   positive   negative    neutral  \\\n",
      "count  18.000000  18.000000  18.000000  18.000000  18.000000  18.000000   \n",
      "mean    8.500000  41.002222  45.946667   0.709199   0.141214   0.149586   \n",
      "std     5.338539  26.117009  26.321784   0.207253   0.154933   0.080974   \n",
      "min     0.000000   0.000000   5.560000   0.236254   0.004977   0.014633   \n",
      "25%     4.250000  19.680000  24.400000   0.587941   0.043334   0.082926   \n",
      "50%     8.500000  40.560000  46.640000   0.739705   0.080390   0.155741   \n",
      "75%    12.750000  62.420000  66.660000   0.870056   0.160178   0.224622   \n",
      "max    17.000000  82.720000  89.000000   0.980389   0.532010   0.267454   \n",
      "\n",
      "       confident   hesitant    concise  enthusiastic  speech_speed  \n",
      "count  18.000000  18.000000  18.000000     18.000000     18.000000  \n",
      "mean    0.733828   0.485172   0.429418      0.466497      3.113771  \n",
      "std     0.208330   0.260785   0.272635      0.286292      0.599958  \n",
      "min     0.286049   0.008425   0.012767      0.088580      2.034884  \n",
      "25%     0.576869   0.342871   0.280775      0.211429      2.605702  \n",
      "50%     0.789854   0.407792   0.441477      0.418900      3.134206  \n",
      "75%     0.898628   0.710799   0.612890      0.686992      3.589744  \n",
      "max     0.980931   0.845698   0.919735      0.990310      4.166667  \n",
      "\n",
      "Table Information for overall_data_1.csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   movie_id            18 non-null     object \n",
      " 1   start               18 non-null     float64\n",
      " 2   end                 18 non-null     float64\n",
      " 3   angry               16 non-null     float64\n",
      " 4   disgust             16 non-null     float64\n",
      " 5   fear                16 non-null     float64\n",
      " 6   happy               16 non-null     float64\n",
      " 7   sad                 16 non-null     float64\n",
      " 8   surprise            16 non-null     float64\n",
      " 9   neutral_emotion     16 non-null     float64\n",
      " 10  gaze                16 non-null     float64\n",
      " 11  blink               16 non-null     float64\n",
      " 12  eye_offset          16 non-null     float64\n",
      " 13  dominant_emotion    16 non-null     object \n",
      " 14  subsequent_emotion  16 non-null     object \n",
      " 15  text                18 non-null     object \n",
      " 16  positive            18 non-null     float64\n",
      " 17  negative            18 non-null     float64\n",
      " 18  neutral_sentiment   18 non-null     float64\n",
      " 19  confident           18 non-null     float64\n",
      " 20  hesitant            18 non-null     float64\n",
      " 21  concise             18 non-null     float64\n",
      " 22  enthusiastic        18 non-null     float64\n",
      " 23  speech_speed        18 non-null     float64\n",
      "dtypes: float64(20), object(4)\n",
      "memory usage: 3.5+ KB\n",
      "None\n",
      "\n",
      "Summary Statistics for overall_data_1.csv:\n",
      "           start        end      angry       disgust       fear      happy  \\\n",
      "count  18.000000  18.000000  16.000000  1.600000e+01  16.000000  16.000000   \n",
      "mean   41.002222  45.946667  12.168539  1.061223e-01  17.372898   7.624052   \n",
      "std    26.117009  26.321784  12.652619  1.762444e-01  20.345720   9.433920   \n",
      "min     0.000000   5.560000   0.164384  6.721490e-08   0.694917   0.004353   \n",
      "25%    19.680000  24.400000   2.589879  1.113827e-03   2.277438   2.209679   \n",
      "50%    40.560000  46.640000   5.626820  4.512160e-02   6.656239   3.651349   \n",
      "75%    62.420000  66.660000  18.547536  1.152906e-01  33.273536   8.646910   \n",
      "max    82.720000  89.000000  35.759961  6.830894e-01  71.000300  34.770630   \n",
      "\n",
      "             sad   surprise  neutral_emotion       gaze  blink  eye_offset  \\\n",
      "count  16.000000  16.000000        16.000000  16.000000   16.0   16.000000   \n",
      "mean    7.498276   4.439327        50.790784   0.531250    0.0   17.634919   \n",
      "std     4.533664   7.947635        27.180048   0.431272    0.0   17.829788   \n",
      "min     0.841330   0.048144         7.800625   0.000000    0.0  -12.120233   \n",
      "25%     4.040653   0.566410        33.945719   0.000000    0.0    2.843150   \n",
      "50%     7.550345   1.050463        50.216725   0.500000    0.0   16.902642   \n",
      "75%    10.494243   2.824894        74.292500   1.000000    0.0   28.464250   \n",
      "max    16.124000  27.311333        96.669600   1.000000    0.0   53.829700   \n",
      "\n",
      "        positive   negative  neutral_sentiment  confident   hesitant  \\\n",
      "count  18.000000  18.000000          18.000000  18.000000  18.000000   \n",
      "mean    0.709199   0.141214           0.149586   0.733828   0.485172   \n",
      "std     0.207253   0.154933           0.080974   0.208330   0.260785   \n",
      "min     0.236254   0.004977           0.014633   0.286049   0.008425   \n",
      "25%     0.587941   0.043334           0.082926   0.576869   0.342871   \n",
      "50%     0.739705   0.080390           0.155741   0.789854   0.407792   \n",
      "75%     0.870056   0.160178           0.224622   0.898628   0.710799   \n",
      "max     0.980389   0.532010           0.267454   0.980931   0.845698   \n",
      "\n",
      "         concise  enthusiastic  speech_speed  \n",
      "count  18.000000     18.000000     18.000000  \n",
      "mean    0.429418      0.466497      3.113771  \n",
      "std     0.272635      0.286292      0.599958  \n",
      "min     0.012767      0.088580      2.034884  \n",
      "25%     0.280775      0.211429      2.605702  \n",
      "50%     0.441477      0.418900      3.134206  \n",
      "75%     0.612890      0.686992      3.589744  \n",
      "max     0.919735      0.990310      4.166667  \n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "merged_emotion_1_path = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\\merged_emotion\\merged_emotion_1.csv\"\n",
    "updated_transcript_1_path = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\\transcript_data\\1_updated.csv\"\n",
    "overall_data_1_path = r\"C:\\Users\\HP\\Desktop\\I'mBesideYou\\overall_data\\overall_data_1.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "merged_emotion_1_df = pd.read_csv(merged_emotion_1_path)\n",
    "updated_transcript_1_df = pd.read_csv(updated_transcript_1_path)\n",
    "overall_data_1_df = pd.read_csv(overall_data_1_path)\n",
    "\n",
    "# Display table information for merged_emotion_1.csv\n",
    "print(\"Table Information for merged_emotion_1.csv:\")\n",
    "print(merged_emotion_1_df.info())\n",
    "print(\"\\nSummary Statistics for merged_emotion_1.csv:\")\n",
    "print(merged_emotion_1_df.describe())\n",
    "\n",
    "# Display table information for 1_updated.csv\n",
    "print(\"\\nTable Information for 1_updated.csv:\")\n",
    "print(updated_transcript_1_df.info())\n",
    "print(\"\\nSummary Statistics for 1_updated.csv:\")\n",
    "print(updated_transcript_1_df.describe())\n",
    "\n",
    "# Display table information for overall_data_1.csv\n",
    "print(\"\\nTable Information for overall_data_1.csv:\")\n",
    "print(overall_data_1_df.info())\n",
    "print(\"\\nSummary Statistics for overall_data_1.csv:\")\n",
    "print(overall_data_1_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61095118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
